<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="John C. Nash" />

<meta name="date" content="2017-06-19" />

<title>nlsr Background, Development, Examples and Discussion</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">nlsr Background, Development, Examples and Discussion</h1>
<h4 class="author"><em>John C. Nash</em></h4>
<h4 class="date"><em>2017-06-19</em></h4>



<p>This rather long vignette is to explain the development and testing of <strong>nlsr</strong>, an R package to try to bring the <strong>R</strong> function nls() up to date and to add capabilities for the extension of the symbolic and automatic derivative tools in <strong>R</strong>.</p>
<p>A particular goal in <strong>nlsr</strong> is to attempt, wherever possible, to use analytic or automatic derivatives. The function nls() uses a rather weak forward derivative approximation. A second objective is to use a Marquardt stabilization of the Gauss-Newton equations to avoid the commonly encountered “singular gradient” failure of nls(). This refers to the loss of rank of the Jacobian at the parameters for evaluation. The particular stabilization also incorporates a very simple trick to avoid very small diagonal elements of the Jacobian inner product, though in the present implementations, this is accomplished indirectly. See the section below <strong>Implementation of method</strong></p>
<p>In preparing the <strong>nlsr</strong> package there is a sub-goal to unify, or at least render compatible, various packages in <strong>R</strong> for the estimation or analysis of problems amenable to nonlinear least squares solution.</p>
<p>A large part of the work for this package – particularly the parts concerning derivatives and R language structures – was initially carried out by Duncan Murdoch. Without his input, much of the capability of the package would not exist.</p>
<p>The package and this vignette are a work in progress, and assistance and examples are welcome. Note that there is similar work in the package Deriv (Andrew Clausen and Serguei Sokol (2015) Symbolic Differentiation, version 2.0, <a href="https://cran.r-project.org/package=Deriv" class="uri">https://cran.r-project.org/package=Deriv</a>), and making the current work “play nicely” with that package is desirable.</p>
<div id="todos" class="section level2">
<h2>TODOS</h2>
<ul>
<li>how to insert numerical derivatives when Deriv unable to get result</li>
<li>approximations for jacfn beyond fwd approximation. How to specify??</li>
</ul>
</div>
<div id="summary-of-capabilities-in-nlsr" class="section level2">
<h2>Summary of capabilities in <code>nlsr</code></h2>
<div id="functions-in-nlsr" class="section level3">
<h3>Functions in <strong>nlsr</strong></h3>
<div id="coef.nlsr" class="section level4">
<h4>coef.nlsr</h4>
<p>extracts and displays the coefficients for a model estimated by nlxb() or nlfb() in the nlsr structured object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nlsr)
ydat&lt;-<span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>,
       <span class="fl">75.995</span>, <span class="fl">91.972</span>)
tdat&lt;-<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>
<span class="co"># try setting t and y here</span>
t &lt;-<span class="st"> </span>tdat
y &lt;-<span class="st"> </span>ydat
sol1 &lt;-<span class="st"> </span><span class="kw">nlxb</span>(y<span class="op">~</span><span class="dv">100</span><span class="op">*</span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="dv">10</span><span class="op">*</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span><span class="fl">0.1</span><span class="op">*</span>b3<span class="op">*</span>t)), <span class="dt">start=</span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">2</span>, <span class="dt">b2=</span><span class="dv">5</span>, <span class="dt">b3=</span><span class="dv">3</span>))</code></pre></div>
<pre><code>## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;t&quot; 
## no weights</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(sol1)</code></pre></div>
<pre><code>##     b1     b2     b3 
## 1.9619 4.9092 3.1357 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">coef</span>(sol1))</code></pre></div>
<pre><code>##     b1     b2     b3 
## 1.9619 4.9092 3.1357 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
</div>
<div id="nlsderiv-codederiv-fnderiv-newderiv" class="section level4">
<h4>nlsDeriv, codeDeriv, fnDeriv, newDeriv</h4>
<p>Functions <strong>Deriv</strong> and <strong>fnDeriv</strong> are designed as replacements for the stats package functions <strong>D</strong> and <strong>deriv</strong> respectively, though the argument lists do not match exactly. <strong>newDeriv</strong> allows additional analytic derivative expressions to be added. The following is an expanded and commented version of the examples from the manual for these functions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(nlsr)
<span class="kw">newDeriv</span>() <span class="co"># a call with no arguments returns a list of available functions</span></code></pre></div>
<pre><code>##  [1] &quot;(&quot;        &quot;*&quot;        &quot;+&quot;        &quot;-&quot;        &quot;/&quot;        &quot;[&quot;       
##  [7] &quot;^&quot;        &quot;abs&quot;      &quot;acos&quot;     &quot;asin&quot;     &quot;atan&quot;     &quot;cos&quot;     
## [13] &quot;cosh&quot;     &quot;digamma&quot;  &quot;dnorm&quot;    &quot;exp&quot;      &quot;gamma&quot;    &quot;lgamma&quot;  
## [19] &quot;log&quot;      &quot;pnorm&quot;    &quot;psigamma&quot; &quot;sign&quot;     &quot;sin&quot;      &quot;sinh&quot;    
## [25] &quot;sqrt&quot;     &quot;tan&quot;      &quot;trigamma&quot; &quot;~&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">           <span class="co"># for which derivatives are currently defined</span>
<span class="kw">newDeriv</span>(<span class="kw">sin</span>(x)) <span class="co"># a call with a function that is in the list of available derivatives</span></code></pre></div>
<pre><code>## $expr
## sin(x)
## 
## $argnames
## [1] &quot;x&quot;
## 
## $required
## [1] 1
## 
## $deriv
## cos(x) * D(x)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">                 <span class="co"># returns the derivative expression for that function</span>
<span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span><span class="kw">sin</span>(x<span class="op">+</span>y), <span class="st">&quot;x&quot;</span>) <span class="co"># partial derivative of this function w.r.t. &quot;x&quot;</span></code></pre></div>
<pre><code>## cos(x + y)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## <span class="al">CAUTION</span> !! ##
<span class="kw">newDeriv</span>(<span class="kw">joe</span>(x)) <span class="co"># but an undefined function returns NULL</span></code></pre></div>
<pre><code>## NULL</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">newDeriv</span>(<span class="kw">joe</span>(x), <span class="dt">deriv=</span><span class="kw">log</span>(x<span class="op">^</span><span class="dv">2</span>)) <span class="co"># We can define derivatives, even if joe(x) is meanin</span>
<span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span><span class="kw">joe</span>(x<span class="op">+</span>z), <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## log((x + z)^2)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Some examples of usage</span>
f &lt;-<span class="st"> </span><span class="cf">function</span>(x) x<span class="op">^</span><span class="dv">2</span>
<span class="kw">newDeriv</span>(<span class="kw">f</span>(x), <span class="dv">2</span><span class="op">*</span>x<span class="op">*</span><span class="kw">D</span>(x))
<span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span><span class="kw">f</span>(<span class="kw">abs</span>(x)), <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## 2 * abs(x) * sign(x)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span>x<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## 2 * x</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span>(<span class="kw">abs</span>(x)<span class="op">^</span><span class="dv">2</span>), <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## 2 * abs(x) * sign(x)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># derivatives of distribution functions</span>
<span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span><span class="kw">pnorm</span>(x, <span class="dt">sd=</span><span class="dv">2</span>, <span class="dt">log =</span> <span class="ot">TRUE</span>), <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## 0.5 * exp(dnorm(x/2, log = TRUE) - pnorm(x/2, log = TRUE))</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get evaluation code from a formula</span>
<span class="kw">codeDeriv</span>(<span class="op">~</span><span class="st"> </span><span class="kw">pnorm</span>(x, <span class="dt">sd =</span> sd, <span class="dt">log =</span> <span class="ot">TRUE</span>), <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## {
##     .expr1 &lt;- x/sd
##     .value &lt;- pnorm(x, sd = sd, log = TRUE)
##     .grad &lt;- array(0, c(length(.value), 1L), list(NULL, &quot;x&quot;))
##     .grad[, &quot;x&quot;] &lt;- 1/sd * exp(dnorm(.expr1, log = TRUE) - pnorm(.expr1, 
##         log = TRUE))
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## }</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># wrap it in a function call</span>
<span class="kw">fnDeriv</span>(<span class="op">~</span><span class="st"> </span><span class="kw">pnorm</span>(x, <span class="dt">sd =</span> sd, <span class="dt">log =</span> <span class="ot">TRUE</span>), <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## function (x, sd) 
## {
##     .expr1 &lt;- x/sd
##     .value &lt;- pnorm(x, sd = sd, log = TRUE)
##     .grad &lt;- array(0, c(length(.value), 1L), list(NULL, &quot;x&quot;))
##     .grad[, &quot;x&quot;] &lt;- 1/sd * exp(dnorm(.expr1, log = TRUE) - pnorm(.expr1, 
##         log = TRUE))
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## }</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="kw">fnDeriv</span>(<span class="op">~</span><span class="st"> </span><span class="kw">pnorm</span>(x, <span class="dt">sd =</span> sd, <span class="dt">log =</span> <span class="ot">TRUE</span>), <span class="st">&quot;x&quot;</span>, <span class="dt">args =</span> <span class="kw">alist</span>(<span class="dt">x =</span>, <span class="dt">sd =</span> <span class="dv">2</span>))
f</code></pre></div>
<pre><code>## function (x, sd = 2) 
## {
##     .expr1 &lt;- x/sd
##     .value &lt;- pnorm(x, sd = sd, log = TRUE)
##     .grad &lt;- array(0, c(length(.value), 1L), list(NULL, &quot;x&quot;))
##     .grad[, &quot;x&quot;] &lt;- 1/sd * exp(dnorm(.expr1, log = TRUE) - pnorm(.expr1, 
##         log = TRUE))
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## }</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">f</span>(<span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] -0.36895
## attr(,&quot;gradient&quot;)
##            x
## [1,] 0.25458</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">100</span><span class="op">*</span>(<span class="kw">f</span>(<span class="fl">1.01</span>) <span class="op">-</span><span class="st"> </span><span class="kw">f</span>(<span class="dv">1</span>))  <span class="co"># Should be close to the gradient</span></code></pre></div>
<pre><code>## [1] 0.25394
## attr(,&quot;gradient&quot;)
##           x
## [1,] 0.2533</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">                      <span class="co"># The attached gradient attribute (from f(1.01)) is</span>
                      <span class="co"># meaningless after the subtraction.</span></code></pre></div>
</div>
<div id="model2rjfun-model2ssgrfun-modelexpr-rjfundoc" class="section level4">
<h4>model2rjfun, model2ssgrfun, modelexpr, rjfundoc</h4>
<p>These functions create functions to evaluate residuals or sums of squares at particular parameter locations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weed &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>,
          <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>)
ii &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">12</span>
wdf &lt;-<span class="st"> </span><span class="kw">data.frame</span>(weed, ii)
wmod &lt;-<span class="st"> </span>weed <span class="op">~</span><span class="st"> </span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>b3<span class="op">*</span>ii))
start1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span><span class="dv">1</span>)
wrj &lt;-<span class="st"> </span><span class="kw">model2rjfun</span>(wmod, start1, <span class="dt">data=</span>wdf)
<span class="kw">print</span>(wrj)</code></pre></div>
<pre><code>## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x4aa5228&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weedux &lt;-<span class="st"> </span><span class="kw">nlxb</span>(wmod, <span class="dt">start=</span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">200</span>, <span class="dt">b2=</span><span class="dv">50</span>, <span class="dt">b3=</span><span class="fl">0.3</span>)) </code></pre></div>
<pre><code>## vn:[1] &quot;weed&quot; &quot;b1&quot;   &quot;b2&quot;   &quot;b3&quot;   &quot;ii&quot;  
## no weights</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(weedux)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  5    Jacobian and  6 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               196.186         11.31      17.35  3.167e-08  -1.334e-10        1011  
## b2               49.0916         1.688      29.08  3.284e-10  -5.431e-11      0.4605  
## b3               0.31357      0.006863      45.69  5.768e-12   3.865e-08     0.04714</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wss &lt;-<span class="st"> </span><span class="kw">model2ssgrfun</span>(wmod, start1, <span class="dt">data=</span>wdf)
<span class="kw">print</span>(wss)</code></pre></div>
<pre><code>## function (prm) 
## {
##     resids &lt;- rjfun(prm)
##     ss &lt;- as.numeric(crossprod(resids))
##     if (gradient) {
##         jacval &lt;- attr(resids, &quot;gradient&quot;)
##         grval &lt;- 2 * as.numeric(crossprod(jacval, resids))
##         attr(ss, &quot;gradient&quot;) &lt;- grval
##     }
##     attr(ss, &quot;resids&quot;) &lt;- resids
##     ss
## }
## &lt;environment: 0x5122a60&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># We can get expressions used to calculate these as follows:</span>
wexpr.rj &lt;-<span class="st"> </span><span class="kw">modelexpr</span>(wrj) 
<span class="kw">print</span>(wexpr.rj)</code></pre></div>
<pre><code>## expression({
##     .expr3 &lt;- exp(-b3 * ii)
##     .expr5 &lt;- 1 + b2 * .expr3
##     .expr10 &lt;- .expr5^2
##     .value &lt;- b1/.expr5 - weed
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;b1&quot;, 
##         &quot;b2&quot;, &quot;b3&quot;)))
##     .grad[, &quot;b1&quot;] &lt;- 1/.expr5
##     .grad[, &quot;b2&quot;] &lt;- -(b1 * .expr3/.expr10)
##     .grad[, &quot;b3&quot;] &lt;- b1 * (b2 * (.expr3 * ii))/.expr10
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## })</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wexpr.ss &lt;-<span class="st"> </span><span class="kw">modelexpr</span>(wss) 
<span class="kw">print</span>(wexpr.ss)</code></pre></div>
<pre><code>## expression({
##     .expr3 &lt;- exp(-b3 * ii)
##     .expr5 &lt;- 1 + b2 * .expr3
##     .expr10 &lt;- .expr5^2
##     .value &lt;- b1/.expr5 - weed
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;b1&quot;, 
##         &quot;b2&quot;, &quot;b3&quot;)))
##     .grad[, &quot;b1&quot;] &lt;- 1/.expr5
##     .grad[, &quot;b2&quot;] &lt;- -(b1 * .expr3/.expr10)
##     .grad[, &quot;b3&quot;] &lt;- b1 * (b2 * (.expr3 * ii))/.expr10
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## })</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wrjdoc &lt;-<span class="st"> </span><span class="kw">rjfundoc</span>(wrj)
<span class="kw">print</span>(wrjdoc)</code></pre></div>
<pre><code>## FUNCTION wrj 
## Formula: weed ~ b1/(1 + b2 * exp(-b3 * ii))
## Code:        expression({
##     .expr3 &lt;- exp(-b3 * ii)
##     .expr5 &lt;- 1 + b2 * .expr3
##     .expr10 &lt;- .expr5^2
##     .value &lt;- b1/.expr5 - weed
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;b1&quot;, 
##         &quot;b2&quot;, &quot;b3&quot;)))
##     .grad[, &quot;b1&quot;] &lt;- 1/.expr5
##     .grad[, &quot;b2&quot;] &lt;- -(b1 * .expr3/.expr10)
##     .grad[, &quot;b3&quot;] &lt;- b1 * (b2 * (.expr3 * ii))/.expr10
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## })
## Parameters:   b1, b2, b3 
## Data:         weed, ii 
## 
## VALUES
## Observations:     12 
## Parameters:
## b1 b2 b3 
##  1  1  1 
## Data (length 12):
##      weed ii
## 1   5.308  1
## 2   7.240  2
## 3   9.638  3
## 4  12.866  4
## 5  17.069  5
## 6  23.192  6
## 7  31.443  7
## 8  38.558  8
## 9  50.156  9
## 10 62.948 10
## 11 75.995 11
## 12 91.972 12</code></pre>
<pre><code>## FUNCTION wrj 
## Formula: weed ~ b1/(1 + b2 * exp(-b3 * ii))
## Code:        expression({
##     .expr3 &lt;- exp(-b3 * ii)
##     .expr5 &lt;- 1 + b2 * .expr3
##     .expr10 &lt;- .expr5^2
##     .value &lt;- b1/.expr5 - weed
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;b1&quot;, 
##         &quot;b2&quot;, &quot;b3&quot;)))
##     .grad[, &quot;b1&quot;] &lt;- 1/.expr5
##     .grad[, &quot;b2&quot;] &lt;- -(b1 * .expr3/.expr10)
##     .grad[, &quot;b3&quot;] &lt;- b1 * (b2 * (.expr3 * ii))/.expr10
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## })
## Parameters:   b1, b2, b3 
## Data:         weed, ii 
## 
## VALUES
## Observations:     12 
## Parameters:
## b1 b2 b3 
##  1  1  1 
## Data (length 12):
##      weed ii
## 1   5.308  1
## 2   7.240  2
## 3   9.638  3
## 4  12.866  4
## 5  17.069  5
## 6  23.192  6
## 7  31.443  7
## 8  38.558  8
## 9  50.156  9
## 10 62.948 10
## 11 75.995 11
## 12 91.972 12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># We do not have similar function for ss functions</span></code></pre></div>
</div>
<div id="nlfb" class="section level4">
<h4>nlfb</h4>
<p>Given a nonlinear model expressed as an expression of the form of a function that computes the residuals from the model and a start vector <code>par</code> , tries to minimize the nonlinear sum of squares of these residuals w.r.t. <code>par</code>. If <code>model(par, mydata)</code> computes an a vector of numbers that are presumed to be able to fit data <code>lhs</code>, then the residual vector is <code>(model(par,mydata) - lhs)</code> , though traditionally we write the negative of this vector. (Writing it this way allows the derivatives of the residuals w.r.t. the parameters <code>par</code> to be the same as those for <code>model(par,mydata).)</code>nlfb` tries to minimize the sum of squares of the residuals with respect to the parameters.</p>
<p>The method takes a parameter <code>jacfn</code> which returns the Jacobian matrix of derivatives of the residuals w.r.t. the parameters in an attribute <code>gradient</code>. If this is NULL, then a numerical approximation to derivatives is used. (??which – and can we use the character method to define these?? What about for nlxb??) Putting the Jacobian in the attribute <code>gradient</code> allows us to combine the computation of the residual and Jacobian in the same code block if we wish, since there are generally common computations, though it does make the setup slightly more complicated. See the example below.</p>
<p>The start vector preferably uses named parameters (especially if there is an underlying formula). The attempted minimization of the sum of squares uses the Nash variant (Nash, 1979) of the Marquardt algorithm, where the linear sub-problem is solved by a qr method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shobbs.res  &lt;-<span class="st">  </span><span class="cf">function</span>(x){ <span class="co"># scaled Hobbs weeds problem -- residual</span>
  <span class="co"># This variant uses looping</span>
  <span class="cf">if</span>(<span class="kw">length</span>(x) <span class="op">!=</span><span class="st"> </span><span class="dv">3</span>) <span class="kw">stop</span>(<span class="st">&quot;hobbs.res -- parameter vector n!=3&quot;</span>)
  y  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, 
           <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>)
  tt  &lt;-<span class="st">  </span><span class="dv">1</span><span class="op">:</span><span class="dv">12</span>
  res  &lt;-<span class="st">  </span><span class="fl">100.0</span><span class="op">*</span>x[<span class="dv">1</span>]<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>x[<span class="dv">2</span>]<span class="op">*</span><span class="dv">10</span>.<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span><span class="fl">0.1</span><span class="op">*</span>x[<span class="dv">3</span>]<span class="op">*</span>tt)) <span class="op">-</span><span class="st"> </span>y
}

shobbs.jac  &lt;-<span class="st">  </span><span class="cf">function</span>(x) { <span class="co"># scaled Hobbs weeds problem -- Jacobian</span>
  jj  &lt;-<span class="st">  </span><span class="kw">matrix</span>(<span class="fl">0.0</span>, <span class="dv">12</span>, <span class="dv">3</span>)
  tt  &lt;-<span class="st">  </span><span class="dv">1</span><span class="op">:</span><span class="dv">12</span>
  yy  &lt;-<span class="st">  </span><span class="kw">exp</span>(<span class="op">-</span><span class="fl">0.1</span><span class="op">*</span>x[<span class="dv">3</span>]<span class="op">*</span>tt)
  zz  &lt;-<span class="st">  </span><span class="fl">100.0</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="dv">10</span>.<span class="op">*</span>x[<span class="dv">2</span>]<span class="op">*</span>yy)
  jj[tt,<span class="dv">1</span>]   &lt;-<span class="st">   </span>zz
  jj[tt,<span class="dv">2</span>]   &lt;-<span class="st">   </span><span class="op">-</span><span class="fl">0.1</span><span class="op">*</span>x[<span class="dv">1</span>]<span class="op">*</span>zz<span class="op">*</span>zz<span class="op">*</span>yy
  jj[tt,<span class="dv">3</span>]   &lt;-<span class="st">   </span><span class="fl">0.01</span><span class="op">*</span>x[<span class="dv">1</span>]<span class="op">*</span>zz<span class="op">*</span>zz<span class="op">*</span>yy<span class="op">*</span>x[<span class="dv">2</span>]<span class="op">*</span>tt
  <span class="kw">attr</span>(jj, <span class="st">&quot;gradient&quot;</span>) &lt;-<span class="st"> </span>jj
  jj
}

<span class="kw">cat</span>(<span class="st">&quot;try nlfb</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## try nlfb</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">st  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span><span class="dv">1</span>)
low  &lt;-<span class="st">  </span><span class="op">-</span><span class="ot">Inf</span>
up &lt;-<span class="st"> </span><span class="ot">Inf</span>
ans1 &lt;-<span class="st"> </span><span class="kw">nlfb</span>(st, shobbs.res, shobbs.jac, <span class="dt">trace=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 10685  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 177800  at  b1 = 7.1383  b2 = 9.1157  b3 = 3.7692  2 / 1
## lamda: 0.01  SS= 19087  at  b1 = 1.4903  b2 = 3.072  b3 = 4.9249  3 / 1
## &lt;&lt;lamda: 0.004  SS= 1273.6  at  b1 = 0.79487  b2 = 2.0743  b3 = 4.761  4 / 1
## lamda: 0.04  SS= 4265  at  b1 = 1.0624  b2 = 1.9667  b3 = 2.3468  5 / 2
## &lt;&lt;lamda: 0.016  SS= 946.57  at  b1 = 0.96631  b2 = 2.7886  b3 = 3.5088  6 / 2
## &lt;&lt;lamda: 0.0064  SS= 43.28  at  b1 = 1.3414  b2 = 4.0037  b3 = 3.5588  7 / 3
## &lt;&lt;lamda: 0.00256  SS= 17.386  at  b1 = 1.5631  b2 = 4.485  b3 = 3.3895  8 / 4
## &lt;&lt;lamda: 0.001024  SS= 6.6368  at  b1 = 1.759  b2 = 4.6938  b3 = 3.2472  9 / 5
## &lt;&lt;lamda: 0.0004096  SS= 3.0719  at  b1 = 1.8946  b2 = 4.8321  b3 = 3.1681  10 / 6
## &lt;&lt;lamda: 0.00016384  SS= 2.5977  at  b1 = 1.9503  b2 = 4.8957  b3 = 3.1413  11 / 7
## &lt;&lt;lamda: 6.5536e-05  SS= 2.5873  at  b1 = 1.961  b2 = 4.9082  b3 = 3.1362  12 / 8
## &lt;&lt;lamda: 2.6214e-05  SS= 2.5873  at  b1 = 1.9618  b2 = 4.9091  b3 = 3.1357  13 / 9
## &lt;&lt;lamda: 1.0486e-05  SS= 2.5873  at  b1 = 1.9619  b2 = 4.9092  b3 = 3.1357  14 / 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ans1)</code></pre></div>
<pre><code>## $residuals
##  [1]  0.011899 -0.032756  0.092029  0.208781  0.392634 -0.057594 -1.105728
##  [8]  0.715787 -0.107646 -0.348395  0.652593 -0.287570
## 
## $sigma
## [1] 0.53617
## 
## $df
## [1] 3 9
## 
## $cov.unscaled
##           b1        b2        b3
## b1  0.044469  0.047830 -0.025280
## b2  0.047830  0.099160 -0.017627
## b3 -0.025280 -0.017627  0.016386
## 
## $param
##    Estimate Std. Error t value   Pr(&gt;|t|)
## b1   1.9619   0.113065  17.352 3.1656e-08
## b2   4.9092   0.168837  29.076 3.2825e-10
## b3   3.1357   0.068633  45.688 5.7677e-12
## 
## $resname
## [1] &quot;ans1&quot;
## 
## $ssquares
## [1] 2.5873
## 
## $nobs
## [1] 12
## 
## $ct
## [1] &quot; &quot; &quot; &quot; &quot; &quot;
## 
## $mt
## [1] &quot; &quot; &quot; &quot; &quot; &quot;
## 
## $Sd
## [1] 130.1161   6.1653   2.7354
## 
## $gr
##             [,1]
## [1,] -7.3274e-06
## [2,]  1.4327e-07
## [3,]  1.7168e-06
## 
## $jeval
## [1] 10
## 
## $feval
## [1] 14
## 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;
## attr(,&quot;class&quot;)
## [1] &quot;summary.nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## No jacobian function -- use internal approximation
ans1n &lt;-<span class="st"> </span><span class="kw">nlfb</span>(st, shobbs.res, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">watch=</span><span class="ot">FALSE</span>)) <span class="co"># NO jacfn</span></code></pre></div>
<pre><code>## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Using default jacobian approximation
## Start:lamda: 1e-04  SS= 10685  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 177800  at  b1 = 7.1383  b2 = 9.1157  b3 = 3.7692  2 / 1
## lamda: 0.01  SS= 19087  at  b1 = 1.4903  b2 = 3.072  b3 = 4.9249  3 / 1
## &lt;&lt;lamda: 0.004  SS= 1273.6  at  b1 = 0.79487  b2 = 2.0743  b3 = 4.761  4 / 1
## lamda: 0.04  SS= 4265  at  b1 = 1.0624  b2 = 1.9667  b3 = 2.3468  5 / 2
## &lt;&lt;lamda: 0.016  SS= 946.57  at  b1 = 0.96631  b2 = 2.7886  b3 = 3.5088  6 / 2
## &lt;&lt;lamda: 0.0064  SS= 43.28  at  b1 = 1.3414  b2 = 4.0037  b3 = 3.5588  7 / 3
## &lt;&lt;lamda: 0.00256  SS= 17.386  at  b1 = 1.5631  b2 = 4.485  b3 = 3.3895  8 / 4
## &lt;&lt;lamda: 0.001024  SS= 6.6368  at  b1 = 1.759  b2 = 4.6938  b3 = 3.2472  9 / 5
## &lt;&lt;lamda: 0.0004096  SS= 3.0719  at  b1 = 1.8946  b2 = 4.8321  b3 = 3.1681  10 / 6
## &lt;&lt;lamda: 0.00016384  SS= 2.5977  at  b1 = 1.9503  b2 = 4.8957  b3 = 3.1413  11 / 7
## &lt;&lt;lamda: 6.5536e-05  SS= 2.5873  at  b1 = 1.961  b2 = 4.9082  b3 = 3.1362  12 / 8
## &lt;&lt;lamda: 2.6214e-05  SS= 2.5873  at  b1 = 1.9618  b2 = 4.9091  b3 = 3.1357  13 / 9
## &lt;&lt;lamda: 1.0486e-05  SS= 2.5873  at  b1 = 1.9619  b2 = 4.9092  b3 = 3.1357  14 / 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ans1n)</code></pre></div>
<pre><code>## $residuals
##  [1]  0.011899 -0.032756  0.092029  0.208781  0.392634 -0.057594 -1.105728
##  [8]  0.715787 -0.107646 -0.348395  0.652593 -0.287570
## 
## $sigma
## [1] 0.53617
## 
## $df
## [1] 3 9
## 
## $cov.unscaled
##           b1        b2        b3
## b1  0.044469  0.047830 -0.025280
## b2  0.047830  0.099160 -0.017627
## b3 -0.025280 -0.017627  0.016386
## 
## $param
##    Estimate Std. Error t value   Pr(&gt;|t|)
## b1   1.9619   0.113065  17.352 3.1656e-08
## b2   4.9092   0.168837  29.076 3.2825e-10
## b3   3.1357   0.068633  45.688 5.7677e-12
## 
## $resname
## [1] &quot;ans1n&quot;
## 
## $ssquares
## [1] 2.5873
## 
## $nobs
## [1] 12
## 
## $ct
## [1] &quot; &quot; &quot; &quot; &quot; &quot;
## 
## $mt
## [1] &quot; &quot; &quot; &quot; &quot; &quot;
## 
## $Sd
## [1] 130.1161   6.1653   2.7354
## 
## $gr
##             [,1]
## [1,] -7.3259e-06
## [2,]  1.4283e-07
## [3,]  1.7190e-06
## 
## $jeval
## [1] 10
## 
## $feval
## [1] 14
## 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;
## attr(,&quot;class&quot;)
## [1] &quot;summary.nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## difference
<span class="kw">coef</span>(ans1)<span class="op">-</span><span class="kw">coef</span>(ans1n)</code></pre></div>
<pre><code>##          b1          b2          b3 
## -1.6018e-09 -2.2231e-09  8.1156e-10 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
</div>
<div id="nlxb" class="section level4">
<h4>nlxb</h4>
<p>Given a nonlinear model expressed as an expression of the form lhs ~ formula_for_rhs and a start vector where parameters used in the model formula are named, attempts to find the minimum of the residual sum of squares using the Nash variant (Nash, 1979) of the Marquardt algorithm, where the linear sub-problem is solved by a qr method. The process is to develop the residual and Jacobian functions using <code>model2rjfun</code>, then call <code>nlfb</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Data for Hobbs problem</span>
ydat  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, 
            <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>) <span class="co"># for testing</span>
tdat  &lt;-<span class="st">  </span><span class="kw">seq_along</span>(ydat) <span class="co"># for testing</span>
start1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span><span class="dv">1</span>)
eunsc  &lt;-<span class="st">   </span>y <span class="op">~</span><span class="st"> </span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>b3<span class="op">*</span>tt))
weeddata1  &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">y=</span>ydat, <span class="dt">tt=</span>tdat)
anlxb1  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(eunsc, <span class="dt">start=</span>start1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## formula: y ~ b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;tt&quot;
## Data variable  y : [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x4b15630&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 23521  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 24356  at  b1 = 50.886  b2 = -240.72  b3 = -372.91  2 / 1
## lamda: 0.01  SS= 24356  at  b1 = 50.183  b2 = -190.69  b3 = -334.2  3 / 1
## lamda: 0.1  SS= 24356  at  b1 = 46.97  b2 = -25.309  b3 = -194.81  4 / 1
## lamda: 1  SS= 24356  at  b1 = 38.096  b2 = 29.924  b3 = -64.262  5 / 1
## lamda: 10  SS= 24353  at  b1 = 18.798  b2 = 3.551  b3 = -2.9011  6 / 1
## &lt;&lt;lamda: 4  SS= 21065  at  b1 = 4.1015  b2 = 0.86688  b3 = 1.3297  7 / 1
## &lt;&lt;lamda: 1.6  SS= 16852  at  b1 = 10.248  b2 = 1.2302  b3 = 1.0044  8 / 2
## lamda: 16  SS= 24078  at  b1 = 20.944  b2 = 2.9473  b3 = -0.40959  9 / 3
## &lt;&lt;lamda: 6.4  SS= 15934  at  b1 = 11.771  b2 = 1.3084  b3 = 0.98087  10 / 3
## &lt;&lt;lamda: 2.56  SS= 14050  at  b1 = 15.152  b2 = 1.6468  b3 = 0.80462  11 / 4
## &lt;&lt;lamda: 1.024  SS= 10985  at  b1 = 22.005  b2 = 2.6632  b3 = 0.45111  12 / 5
## &lt;&lt;lamda: 0.4096  SS= 6427.1  at  b1 = 35.128  b2 = 4.7135  b3 = 0.50974  13 / 6
## &lt;&lt;lamda: 0.16384  SS= 4725  at  b1 = 52.285  b2 = 9.2948  b3 = 0.31348  14 / 7
## &lt;&lt;lamda: 0.065536  SS= 1132.2  at  b1 = 76.446  b2 = 15.142  b3 = 0.41095  15 / 8
## &lt;&lt;lamda: 0.026214  SS= 518.76  at  b1 = 96.924  b2 = 24.422  b3 = 0.35816  16 / 9
## &lt;&lt;lamda: 0.010486  SS= 79.464  at  b1 = 122.18  b2 = 35.262  b3 = 0.36484  17 / 10
## &lt;&lt;lamda: 0.0041943  SS= 26.387  at  b1 = 141.55  b2 = 42.387  b3 = 0.35215  18 / 11
## &lt;&lt;lamda: 0.0016777  SS= 11.339  at  b1 = 160.02  b2 = 45.519  b3 = 0.33738  19 / 12
## &lt;&lt;lamda: 0.00067109  SS= 5.2767  at  b1 = 176.92  b2 = 47.037  b3 = 0.32443  20 / 13
## &lt;&lt;lamda: 0.00026844  SS= 2.9656  at  b1 = 189.12  b2 = 48.279  b3 = 0.31712  21 / 14
## &lt;&lt;lamda: 0.00010737  SS= 2.6003  at  b1 = 194.72  b2 = 48.92  b3 = 0.31429  22 / 15
## &lt;&lt;lamda: 4.295e-05  SS= 2.5873  at  b1 = 196.04  b2 = 49.075  b3 = 0.31364  23 / 16
## &lt;&lt;lamda: 1.718e-05  SS= 2.5873  at  b1 = 196.18  b2 = 49.091  b3 = 0.31357  24 / 17
## &lt;&lt;lamda: 6.8719e-06  SS= 2.5873  at  b1 = 196.19  b2 = 49.092  b3 = 0.31357  25 / 18</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(anlxb1)</code></pre></div>
<pre><code>## $residuals
##  [1]  0.011898 -0.032757  0.092028  0.208780  0.392633 -0.057594 -1.105727
##  [8]  0.715788 -0.107645 -0.348394  0.652593 -0.287572
## attr(,&quot;gradient&quot;)
##             b1       b2       b3
##  [1,] 0.027117 -0.10543   5.1756
##  [2,] 0.036737 -0.14142  13.8849
##  [3,] 0.049596 -0.18837  27.7424
##  [4,] 0.066645 -0.24858  48.8137
##  [5,] 0.089005 -0.32404  79.5373
##  [6,] 0.117921 -0.41568 122.4383
##  [7,] 0.154635 -0.52241 179.5224
##  [8,] 0.200186 -0.63986 251.2937
##  [9,] 0.255107 -0.75941 335.5262
## [10,] 0.319083 -0.86828 426.2515
## [11,] 0.390688 -0.95133 513.7251
## [12,] 0.467334 -0.99482 586.0462
## 
## $sigma
## [1] 0.53617
## 
## $df
## [1] 3 9
## 
## $cov.unscaled
##           b1        b2          b3
## b1 444.64742 47.824220 -0.25278540
## b2  47.82422  9.915178 -0.01762507
## b3  -0.25279 -0.017625  0.00016386
## 
## $param
##     Estimate Std. Error t value   Pr(&gt;|t|)
## b1 196.18612 11.3059779  17.352 3.1644e-08
## b2  49.09162  1.6883034  29.077 3.2813e-10
## b3   0.31357  0.0068633  45.688 5.7678e-12
## 
## $resname
## [1] &quot;anlxb1&quot;
## 
## $ssquares
## [1] 2.5873
## 
## $nobs
## [1] 12
## 
## $ct
## [1] &quot; &quot; &quot; &quot; &quot; &quot;
## 
## $mt
## [1] &quot; &quot; &quot; &quot; &quot; &quot;
## 
## $Sd
## [1] 1.0108e+03 4.6047e-01 4.7148e-02
## 
## $gr
##           [,1]
## b1 -2.6627e-07
## b2  1.5901e-07
## b3 -5.5308e-05
## 
## $jeval
## [1] 18
## 
## $feval
## [1] 25
## 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;
## attr(,&quot;class&quot;)
## [1] &quot;summary.nlsr&quot;</code></pre>
</div>
<div id="print.nlsr" class="section level4">
<h4>print.nlsr</h4>
<p>Print summary output (but involving some serious computations!) of an object of class nlsr from  or  from package .</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### From examples above
<span class="kw">print</span>(weedux)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  5    Jacobian and  6 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               196.186         11.31      17.35  3.167e-08  -1.334e-10        1011  
## b2               49.0916         1.688      29.08  3.284e-10  -5.431e-11      0.4605  
## b3               0.31357      0.006863      45.69  5.768e-12   3.865e-08     0.04714</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(ans1)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  10    Jacobian and  14 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               1.96186        0.1131      17.35  3.166e-08  -7.327e-06       130.1  
## b2               4.90916        0.1688      29.08  3.282e-10   1.433e-07       6.165  
## b3                3.1357       0.06863      45.69  5.768e-12   1.717e-06       2.735</code></pre>
</div>
<div id="resgr-resss" class="section level4">
<h4>resgr, resss</h4>
<p>For a nonlinear model originally expressed as an expression of the form lhs ~ formula_for_rhs assume we have a resfn and jacfn that compute the residuals and the Jacobian at a set of parameters. This routine computes the gradient, that is, t(Jacobian) %*% residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Use shobbs example
RG &lt;-<span class="st"> </span><span class="kw">resgr</span>(st, shobbs.res, shobbs.jac)
RG</code></pre></div>
<pre><code>## [1] -10091.3   7835.3  -8234.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SS &lt;-<span class="st"> </span><span class="kw">resss</span>(st, shobbs.res)
SS</code></pre></div>
<pre><code>## [1] 10685</code></pre>
</div>
<div id="nlssimplify-and-related-functions" class="section level4">
<h4>nlsSimplify and related functions</h4>
<p>Simplifications to render derivative expresssions more usable.</p>
<p>The related tools are: <strong>newSimplification, sysSimplifications, isFALSE, isZERO, isONE, isMINUSONE, isCALL, findSubexprs, sysDerivs</strong>.</p>
<p><strong>nlsSimplify</strong> simplifies expressions according to rules specified by <strong>newSimplification</strong>.</p>
<p><strong>findSubexprs</strong> finds common subexpressions in an expression vector so that duplicate computation can be avoided.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## nlsSimplify
<span class="kw">nlsSimplify</span>(<span class="kw">quote</span>(a <span class="op">+</span><span class="st"> </span><span class="dv">0</span>))</code></pre></div>
<pre><code>## a</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nlsSimplify</span>(<span class="kw">quote</span>(<span class="kw">exp</span>(<span class="dv">1</span>)), <span class="dt">verbose =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Simplifying exp(1)</code></pre>
<pre><code>## Applying simplification:</code></pre>
<pre><code>## $expr
## exp(a)
## 
## $argnames
## [1] &quot;a&quot;
## 
## $test
## is.numeric(a)
## 
## $simplification
## exp(a)
## 
## $do_eval
## [1] TRUE</code></pre>
<pre><code>## [1] 2.7183</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nlsSimplify</span>(<span class="kw">quote</span>(<span class="kw">sqrt</span>(a <span class="op">+</span><span class="st"> </span>b)))  <span class="co"># standard rule</span></code></pre></div>
<pre><code>## sqrt(a + b)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## sysSimplifications
<span class="co"># creates a new environment whose parent is emptyenv()  Why??</span>
<span class="kw">str</span>(sysSimplifications)</code></pre></div>
<pre><code>## &lt;environment: 0x42beda0&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">myrules &lt;-<span class="st"> </span><span class="kw">new.env</span>(<span class="dt">parent =</span> sysSimplifications)
## newSimplification
<span class="kw">newSimplification</span>(<span class="kw">sqrt</span>(a), <span class="ot">TRUE</span>, a<span class="op">^</span><span class="fl">0.5</span>, <span class="dt">simpEnv =</span> myrules)
<span class="kw">nlsSimplify</span>(<span class="kw">quote</span>(<span class="kw">sqrt</span>(a <span class="op">+</span><span class="st"> </span>b)), <span class="dt">simpEnv =</span> myrules)</code></pre></div>
<pre><code>## (a + b)^0.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## isFALSE
<span class="kw">print</span>(<span class="kw">isFALSE</span>(<span class="dv">1</span><span class="op">==</span><span class="dv">2</span>))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isFALSE</span>(<span class="dv">2</span><span class="op">==</span><span class="dv">2</span>))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## isZERO
<span class="kw">print</span>(<span class="kw">isZERO</span>(<span class="dv">0</span>))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">0</span>
<span class="kw">print</span>(<span class="kw">isZERO</span>(x))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">0</span>
<span class="kw">print</span>(<span class="kw">isZERO</span>(x))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isZERO</span>(<span class="op">~</span>(<span class="op">-</span><span class="dv">1</span>)))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isZERO</span>(<span class="st">&quot;-1&quot;</span>))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isZERO</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">1</span>)))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## isONE
<span class="kw">print</span>(<span class="kw">isONE</span>(<span class="dv">1</span>))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span>
<span class="kw">print</span>(<span class="kw">isONE</span>(x))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isONE</span>(<span class="op">~</span>(<span class="dv">1</span>)))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isONE</span>(<span class="st">&quot;1&quot;</span>))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isONE</span>(<span class="kw">expression</span>(<span class="dv">1</span>)))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## isMINUSONE
<span class="kw">print</span>(<span class="kw">isMINUSONE</span>(<span class="op">-</span><span class="dv">1</span>))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">1</span>
<span class="kw">print</span>(<span class="kw">isMINUSONE</span>(x))</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isMINUSONE</span>(<span class="op">~</span>(<span class="op">-</span><span class="dv">1</span>)))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isMINUSONE</span>(<span class="st">&quot;-1&quot;</span>))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isMINUSONE</span>(<span class="kw">expression</span>(<span class="op">-</span><span class="dv">1</span>)))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## isCALL  ?? don't have good understanding of this
x &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">1</span>
<span class="kw">print</span>(<span class="kw">isCALL</span>(x,<span class="st">&quot;isMINUSONE&quot;</span>))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">isCALL</span>(x, <span class="kw">quote</span>(isMINUSONE)))</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## findSubexprs
<span class="kw">findSubexprs</span>(<span class="kw">expression</span>(x<span class="op">^</span><span class="dv">2</span>, x<span class="op">-</span>y, y<span class="op">^</span><span class="dv">2</span><span class="op">-</span>x<span class="op">^</span><span class="dv">2</span>))</code></pre></div>
<pre><code>## {
##     .expr1 &lt;- x^2
##     expression(.expr1, x - y, y^2 - .expr1)
## }</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## sysDerivs
<span class="co"># creates a new environment whose parent is emptyenv()  Why??</span>
<span class="kw">str</span>(sysDerivs)</code></pre></div>
<pre><code>## &lt;environment: 0x4f8fa28&gt;</code></pre>
</div>
<div id="summary.nlsr" class="section level4">
<h4>summary.nlsr</h4>
<p>Provide a summary output (but involving some serious computations!) of an object of class nlsr from nlxb or nlfb from package nlsr. Examples have been given above under <strong>nlxb</strong> and <strong>nlfb</strong>.</p>
</div>
<div id="wrapnlsr" class="section level4">
<h4>wrapnlsr</h4>
<p>Given a nonlinear model expressed as an expression of the form</p>
<pre><code>lhs ~ formula_for_rhs</code></pre>
<p>and a start vector where parameters used in the model formula are named, attempts to find the minimum of the residual sum of squares using the Nash variant (Nash, 1979) of the Marquardt algorithm, where the linear sub-problem is solved by a qr method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Data for Hobbs problem</span>
ydat  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, 
            <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>) <span class="co"># for testing</span>
tdat  &lt;-<span class="st">  </span><span class="kw">seq_along</span>(ydat) <span class="co"># for testing</span>
start1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span><span class="dv">1</span>)
eunsc  &lt;-<span class="st">   </span>y <span class="op">~</span><span class="st"> </span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>b3<span class="op">*</span>tt))
weeddata1  &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">y=</span>ydat, <span class="dt">tt=</span>tdat)
## The following attempt with nls() fails!
anls1  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nls</span>(eunsc, <span class="dt">start=</span>start1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## 23521 :  1 1 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## But we succeed by calling nlxb first.
anlxb1  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(eunsc, <span class="dt">start=</span>start1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## formula: y ~ b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;tt&quot;
## Data variable  y : [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x4f75120&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 23521  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 24356  at  b1 = 50.886  b2 = -240.72  b3 = -372.91  2 / 1
## lamda: 0.01  SS= 24356  at  b1 = 50.183  b2 = -190.69  b3 = -334.2  3 / 1
## lamda: 0.1  SS= 24356  at  b1 = 46.97  b2 = -25.309  b3 = -194.81  4 / 1
## lamda: 1  SS= 24356  at  b1 = 38.096  b2 = 29.924  b3 = -64.262  5 / 1
## lamda: 10  SS= 24353  at  b1 = 18.798  b2 = 3.551  b3 = -2.9011  6 / 1
## &lt;&lt;lamda: 4  SS= 21065  at  b1 = 4.1015  b2 = 0.86688  b3 = 1.3297  7 / 1
## &lt;&lt;lamda: 1.6  SS= 16852  at  b1 = 10.248  b2 = 1.2302  b3 = 1.0044  8 / 2
## lamda: 16  SS= 24078  at  b1 = 20.944  b2 = 2.9473  b3 = -0.40959  9 / 3
## &lt;&lt;lamda: 6.4  SS= 15934  at  b1 = 11.771  b2 = 1.3084  b3 = 0.98087  10 / 3
## &lt;&lt;lamda: 2.56  SS= 14050  at  b1 = 15.152  b2 = 1.6468  b3 = 0.80462  11 / 4
## &lt;&lt;lamda: 1.024  SS= 10985  at  b1 = 22.005  b2 = 2.6632  b3 = 0.45111  12 / 5
## &lt;&lt;lamda: 0.4096  SS= 6427.1  at  b1 = 35.128  b2 = 4.7135  b3 = 0.50974  13 / 6
## &lt;&lt;lamda: 0.16384  SS= 4725  at  b1 = 52.285  b2 = 9.2948  b3 = 0.31348  14 / 7
## &lt;&lt;lamda: 0.065536  SS= 1132.2  at  b1 = 76.446  b2 = 15.142  b3 = 0.41095  15 / 8
## &lt;&lt;lamda: 0.026214  SS= 518.76  at  b1 = 96.924  b2 = 24.422  b3 = 0.35816  16 / 9
## &lt;&lt;lamda: 0.010486  SS= 79.464  at  b1 = 122.18  b2 = 35.262  b3 = 0.36484  17 / 10
## &lt;&lt;lamda: 0.0041943  SS= 26.387  at  b1 = 141.55  b2 = 42.387  b3 = 0.35215  18 / 11
## &lt;&lt;lamda: 0.0016777  SS= 11.339  at  b1 = 160.02  b2 = 45.519  b3 = 0.33738  19 / 12
## &lt;&lt;lamda: 0.00067109  SS= 5.2767  at  b1 = 176.92  b2 = 47.037  b3 = 0.32443  20 / 13
## &lt;&lt;lamda: 0.00026844  SS= 2.9656  at  b1 = 189.12  b2 = 48.279  b3 = 0.31712  21 / 14
## &lt;&lt;lamda: 0.00010737  SS= 2.6003  at  b1 = 194.72  b2 = 48.92  b3 = 0.31429  22 / 15
## &lt;&lt;lamda: 4.295e-05  SS= 2.5873  at  b1 = 196.04  b2 = 49.075  b3 = 0.31364  23 / 16
## &lt;&lt;lamda: 1.718e-05  SS= 2.5873  at  b1 = 196.18  b2 = 49.091  b3 = 0.31357  24 / 17
## &lt;&lt;lamda: 6.8719e-06  SS= 2.5873  at  b1 = 196.19  b2 = 49.092  b3 = 0.31357  25 / 18</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">st2 &lt;-<span class="st"> </span><span class="kw">coef</span>(anlxb1)
anls2  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nls</span>(eunsc, <span class="dt">start=</span>st2, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## 2.5873 :  196.18612  49.09162   0.31357</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Or we can simply call wrapnlsr
anls2a  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">wrapnlsr</span>(eunsc, <span class="dt">start=</span>start1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## wrapnls call with lower=[1] -Inf -Inf -Inf
## and upper=[1] Inf Inf Inf
## formula: y ~ b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;tt&quot;
## Data variable  y : [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x4768348&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 23521  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 24356  at  b1 = 50.886  b2 = -240.72  b3 = -372.91  2 / 1
## lamda: 0.01  SS= 24356  at  b1 = 50.183  b2 = -190.69  b3 = -334.2  3 / 1
## lamda: 0.1  SS= 24356  at  b1 = 46.97  b2 = -25.309  b3 = -194.81  4 / 1
## lamda: 1  SS= 24356  at  b1 = 38.096  b2 = 29.924  b3 = -64.262  5 / 1
## lamda: 10  SS= 24353  at  b1 = 18.798  b2 = 3.551  b3 = -2.9011  6 / 1
## &lt;&lt;lamda: 4  SS= 21065  at  b1 = 4.1015  b2 = 0.86688  b3 = 1.3297  7 / 1
## &lt;&lt;lamda: 1.6  SS= 16852  at  b1 = 10.248  b2 = 1.2302  b3 = 1.0044  8 / 2
## lamda: 16  SS= 24078  at  b1 = 20.944  b2 = 2.9473  b3 = -0.40959  9 / 3
## &lt;&lt;lamda: 6.4  SS= 15934  at  b1 = 11.771  b2 = 1.3084  b3 = 0.98087  10 / 3
## &lt;&lt;lamda: 2.56  SS= 14050  at  b1 = 15.152  b2 = 1.6468  b3 = 0.80462  11 / 4
## &lt;&lt;lamda: 1.024  SS= 10985  at  b1 = 22.005  b2 = 2.6632  b3 = 0.45111  12 / 5
## &lt;&lt;lamda: 0.4096  SS= 6427.1  at  b1 = 35.128  b2 = 4.7135  b3 = 0.50974  13 / 6
## &lt;&lt;lamda: 0.16384  SS= 4725  at  b1 = 52.285  b2 = 9.2948  b3 = 0.31348  14 / 7
## &lt;&lt;lamda: 0.065536  SS= 1132.2  at  b1 = 76.446  b2 = 15.142  b3 = 0.41095  15 / 8
## &lt;&lt;lamda: 0.026214  SS= 518.76  at  b1 = 96.924  b2 = 24.422  b3 = 0.35816  16 / 9
## &lt;&lt;lamda: 0.010486  SS= 79.464  at  b1 = 122.18  b2 = 35.262  b3 = 0.36484  17 / 10
## &lt;&lt;lamda: 0.0041943  SS= 26.387  at  b1 = 141.55  b2 = 42.387  b3 = 0.35215  18 / 11
## &lt;&lt;lamda: 0.0016777  SS= 11.339  at  b1 = 160.02  b2 = 45.519  b3 = 0.33738  19 / 12
## &lt;&lt;lamda: 0.00067109  SS= 5.2767  at  b1 = 176.92  b2 = 47.037  b3 = 0.32443  20 / 13
## &lt;&lt;lamda: 0.00026844  SS= 2.9656  at  b1 = 189.12  b2 = 48.279  b3 = 0.31712  21 / 14
## &lt;&lt;lamda: 0.00010737  SS= 2.6003  at  b1 = 194.72  b2 = 48.92  b3 = 0.31429  22 / 15
## &lt;&lt;lamda: 4.295e-05  SS= 2.5873  at  b1 = 196.04  b2 = 49.075  b3 = 0.31364  23 / 16
## &lt;&lt;lamda: 1.718e-05  SS= 2.5873  at  b1 = 196.18  b2 = 49.091  b3 = 0.31357  24 / 17
## &lt;&lt;lamda: 6.8719e-06  SS= 2.5873  at  b1 = 196.19  b2 = 49.092  b3 = 0.31357  25 / 18
## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  18    Jacobian and  25 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               196.186         11.31      17.35  3.164e-08  -2.663e-07        1011  
## b2               49.0916         1.688      29.08  3.281e-10    1.59e-07      0.4605  
## b3               0.31357      0.006863      45.69  5.768e-12  -5.531e-05     0.04715  
## newstart:       b1        b2        b3 
## 196.18612  49.09162   0.31357 
## nls call with no bounds
## 2.5873 :  196.18612  49.09162   0.31357</code></pre>
</div>
</div>
<div id="particular-features" class="section level3">
<h3>Particular features</h3>
<div id="weighted-nonlinear-regression" class="section level4">
<h4>weighted nonlinear regression</h4>
<p>Weighted regression alters the sum of squares of the parameters <code>prm</code> from</p>
<pre><code> sum_{i} (residual_i(prm)^2)</code></pre>
<p>to</p>
<pre><code> sum_{i} (wts_i * residual_i(prm)^2)</code></pre>
<p>where <code>wts</code> is the vector of weights. This is equivalent to multiplying each residual or row of the Jacobian by the square root of the respective weight.</p>
<p>While <code>nls()</code> has provision for (fixed) weights, the example given in the documentation of <code>nls()</code> for weighted regression actually uses a functional form. Moreover, the weights are the square roots of the <strong>predicted</strong> or model values, so are not fixed. Here we replace these weights with the fixed values of the quantity we are trying to predict, namely the <code>rate</code> variable in a kinetic model. In our example below we first use the documentation example with predicted values; note that the name of the result has been changed from that in the <code>nls()</code> documentation. This result gives different estimates of the parameters from the fixed weights used afterwards.</p>
<p>Note that neither <code>nlsr::nlxb</code> nor <code>nlsr::nlfb</code> can use the weighted.MM function directly. This is one of the more awkward aspects of nonlinear least squares and nonlinear optimization.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Treated &lt;-<span class="st"> </span>Puromycin[Puromycin<span class="op">$</span>state <span class="op">==</span><span class="st"> &quot;treated&quot;</span>, ]
weighted.MM &lt;-<span class="st"> </span><span class="cf">function</span>(resp, conc, Vm, K)
{
  ## Purpose: exactly as white book p. 451 -- RHS for nls()
  ##  Weighted version of Michaelis-Menten model
  ## ----------------------------------------------------------
  ## Arguments: 'y', 'x' and the two parameters (see book)
  ## ----------------------------------------------------------
  ## Author: Martin Maechler, Date: 23 Mar 2001
  
  pred &lt;-<span class="st"> </span>(Vm <span class="op">*</span><span class="st"> </span>conc)<span class="op">/</span>(K <span class="op">+</span><span class="st"> </span>conc)
  (resp <span class="op">-</span><span class="st"> </span>pred) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(pred)
}
## Here is the estimation using predicted value weights
Pur.wtnlspred &lt;-<span class="st"> </span><span class="kw">nls</span>( <span class="op">~</span><span class="st"> </span><span class="kw">weighted.MM</span>(rate, conc, Vm, K), <span class="dt">data =</span> Treated,
               <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">Vm =</span> <span class="dv">200</span>, <span class="dt">K =</span> <span class="fl">0.1</span>))
<span class="kw">summary</span>(Pur.wtnlspred)</code></pre></div>
<pre><code>## 
## Formula: 0 ~ weighted.MM(rate, conc, Vm, K)
## 
## Parameters:
##    Estimate Std. Error t value Pr(&gt;|t|)    
## Vm 2.07e+02   9.22e+00   22.42  7.0e-10 ***
## K  5.46e-02   7.98e-03    6.84  4.5e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.21 on 10 degrees of freedom
## 
## Number of iterations to convergence: 5 
## Achieved convergence tolerance: 3.86e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## nlxb cannog use this form
Pur.wtnlxbpred &lt;-<span class="st"> </span><span class="kw">try</span>(<span class="kw">nlxb</span>( <span class="op">~</span><span class="st"> </span><span class="kw">weighted.MM</span>(rate, conc, Vm, K), <span class="dt">data =</span> Treated,
               <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">Vm =</span> <span class="dv">200</span>, <span class="dt">K =</span> <span class="fl">0.1</span>)))</code></pre></div>
<pre><code>## vn:[1] &quot;rate&quot; &quot;conc&quot; &quot;Vm&quot;   &quot;K&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## and the structure is wrong for nlfb. See wres.MM below.
Pur.wtnlfbpred &lt;-<span class="st"> </span><span class="kw">try</span>(<span class="kw">nlfb</span>(<span class="dt">resfn=</span><span class="kw">weighted.MM</span>(rate, conc, Vm, K), <span class="dt">data =</span> Treated,
               <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">Vm =</span> <span class="dv">200</span>, <span class="dt">K =</span> <span class="fl">0.1</span>)))</code></pre></div>
<pre><code>## no weights</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Now use fixed weights and the weights argument in nls()
Pur.wnls &lt;-<span class="st"> </span><span class="kw">nls</span>( rate <span class="op">~</span><span class="st"> </span>(Vm <span class="op">*</span><span class="st"> </span>conc)<span class="op">/</span>(K <span class="op">+</span><span class="st"> </span>conc), <span class="dt">data =</span> Treated,
                  <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">Vm =</span> <span class="dv">200</span>, <span class="dt">K =</span> <span class="fl">0.1</span>), <span class="dt">weights=</span><span class="dv">1</span><span class="op">/</span>rate)
<span class="kw">summary</span>(Pur.wnls)</code></pre></div>
<pre><code>## 
## Formula: rate ~ (Vm * conc)/(K + conc)
## 
## Parameters:
##    Estimate Std. Error t value Pr(&gt;|t|)    
## Vm 2.10e+02   9.01e+00   23.27  4.9e-10 ***
## K  6.07e-02   8.39e-03    7.23  2.8e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.11 on 10 degrees of freedom
## 
## Number of iterations to convergence: 7 
## Achieved convergence tolerance: 9.48e-07</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## nlsr::nlxb should give essentially the same result
<span class="kw">library</span>(nlsr)
## Note that we put in the dataframe name to explicitly specify weights
Pur.wnlxb &lt;-<span class="st"> </span><span class="kw">nlxb</span>( rate <span class="op">~</span><span class="st"> </span>(Vm <span class="op">*</span><span class="st"> </span>conc)<span class="op">/</span>(K <span class="op">+</span><span class="st"> </span>conc), <span class="dt">data =</span> Treated,
                <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">Vm =</span> <span class="dv">200</span>, <span class="dt">K =</span> <span class="fl">0.1</span>), <span class="dt">weights=</span><span class="dv">1</span><span class="op">/</span>Treated<span class="op">$</span>rate)</code></pre></div>
<pre><code>## vn:[1] &quot;rate&quot; &quot;Vm&quot;   &quot;conc&quot; &quot;K&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Pur.wnlxb)</code></pre></div>
<pre><code>## $residuals
##  [1] -2.755920  0.725597  0.734149 -0.267735  1.091190 -0.330634  0.420283
##  [8]  0.997627 -0.136479 -0.838386 -0.580807 -0.095909
## attr(,&quot;gradient&quot;)
##            Vm       K
##  [1,] 0.24797 -644.41
##  [2,] 0.24797 -644.41
##  [3,] 0.49729 -863.88
##  [4,] 0.49729 -863.88
##  [5,] 0.64458 -791.67
##  [6,] 0.64458 -791.67
##  [7,] 0.78388 -585.42
##  [8,] 0.78388 -585.42
##  [9,] 0.90227 -304.70
## [10,] 0.90227 -304.70
## [11,] 0.94774 -171.15
## [12,] 0.94774 -171.15
## 
## $sigma
## [1] 1.1078
## 
## $df
## [1]  2 10
## 
## $cov.unscaled
##           Vm          K
## Vm 66.088987 4.7937e-02
## K   0.047937 5.7385e-05
## 
## $param
##      Estimate Std. Error t value   Pr(&gt;|t|)
## Vm 209.596813  9.0058754 23.2733 4.8539e-10
## K    0.060654  0.0083919  7.2276 2.8322e-05
## 
## $resname
## [1] &quot;Pur.wnlxb&quot;
## 
## $ssquares
## [1] 12.272
## 
## $nobs
## [1] 12
## 
## $ct
## [1] &quot; &quot; &quot; &quot;
## 
## $mt
## [1] &quot; &quot; &quot; &quot;
## 
## $Sd
## [1] 210.28210   0.12301
## 
## $gr
##           [,1]
## Vm -3.5808e-12
## K  -3.1367e-10
## 
## $jeval
## [1] 8
## 
## $feval
## [1] 9
## 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;
## attr(,&quot;class&quot;)
## [1] &quot;summary.nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## check difference
<span class="kw">coef</span>(Pur.wnls) <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(Pur.wnlxb)</code></pre></div>
<pre><code>##          Vm           K 
## -2.0921e-05 -2.5056e-08 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Residuals Pur.wnls -- These are weighted
## resid(Pur.wnlxb) # ?? does not work -- why?
<span class="kw">print</span>(<span class="kw">res</span>(Pur.wnlxb))</code></pre></div>
<pre><code>##  [1] -2.755920  0.725597  0.734149 -0.267735  1.091190 -0.330634  0.420283
##  [8]  0.997627 -0.136479 -0.838386 -0.580807 -0.095909
## attr(,&quot;gradient&quot;)
##            Vm       K
##  [1,] 0.24797 -644.41
##  [2,] 0.24797 -644.41
##  [3,] 0.49729 -863.88
##  [4,] 0.49729 -863.88
##  [5,] 0.64458 -791.67
##  [6,] 0.64458 -791.67
##  [7,] 0.78388 -585.42
##  [8,] 0.78388 -585.42
##  [9,] 0.90227 -304.70
## [10,] 0.90227 -304.70
## [11,] 0.94774 -171.15
## [12,] 0.94774 -171.15</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Those from nls() are NOT weighted
<span class="kw">resid</span>(Pur.wnls)</code></pre></div>
<pre><code>##  [1]  24.0255  -4.9745  -7.2305   2.7695 -12.1019   3.8981  -5.2996
##  [8] -12.2996   1.8862  11.8862   8.3564   1.3564
## attr(,&quot;label&quot;)
## [1] &quot;Residuals&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Try using a function, that is nlsr::nlfb
stw &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">Vm =</span> <span class="dv">200</span>, <span class="dt">K =</span> <span class="fl">0.1</span>)
wres.MM &lt;-<span class="st"> </span><span class="cf">function</span>(prm, rate, conc) {
      Vm &lt;-<span class="st"> </span>prm[<span class="dv">1</span>]
      K &lt;-<span class="st"> </span>prm[<span class="dv">2</span>]
      pred &lt;-<span class="st"> </span>(Vm <span class="op">*</span><span class="st"> </span>conc)<span class="op">/</span>(K <span class="op">+</span><span class="st"> </span>conc)
    (rate <span class="op">-</span><span class="st"> </span>pred) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(rate) <span class="co"># </span><span class="al">NOTE</span><span class="co">: NOT pred here</span>
}

<span class="co"># test function first to see it works</span>
<span class="kw">print</span>(<span class="kw">wres.MM</span>(stw, <span class="dt">rate=</span>Treated<span class="op">$</span>rate, <span class="dt">conc=</span>Treated<span class="op">$</span>conc))</code></pre></div>
<pre><code>##  [1] 4.8942 1.9935 2.2338 3.0936 1.6445 2.9040 1.7051 1.1761 1.5414 2.2079
## [11] 1.6449 1.1785</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Pur.wnlfb &lt;-<span class="st"> </span><span class="kw">nlfb</span>(<span class="dt">start=</span>stw,  <span class="dt">resfn=</span>wres.MM, <span class="dt">rate =</span> Treated<span class="op">$</span>rate, <span class="dt">conc=</span>Treated<span class="op">$</span>conc, 
                  <span class="dt">trace=</span><span class="ot">FALSE</span>) <span class="co"># Note: weights are inside function already here</span></code></pre></div>
<pre><code>## no weights</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Pur.wnlfb)</code></pre></div>
<pre><code>## $residuals
##  [1]  2.755920 -0.725597 -0.734149  0.267735 -1.091190  0.330634 -0.420283
##  [8] -0.997627  0.136479  0.838386  0.580807  0.095909
## 
## $sigma
## [1] 1.1078
## 
## $df
## [1]  2 10
## 
## $cov.unscaled
##           Vm          K
## Vm 66.088990 4.7937e-02
## K   0.047937 5.7385e-05
## 
## $param
##      Estimate Std. Error t value   Pr(&gt;|t|)
## Vm 209.596813  9.0058756 23.2733 4.8539e-10
## K    0.060654  0.0083919  7.2276 2.8322e-05
## 
## $resname
## [1] &quot;Pur.wnlfb&quot;
## 
## $ssquares
## [1] 12.272
## 
## $nobs
## [1] 12
## 
## $ct
## [1] &quot; &quot; &quot; &quot;
## 
## $mt
## [1] &quot; &quot; &quot; &quot;
## 
## $Sd
## [1] 210.28209   0.12301
## 
## $gr
##             [,1]
## [1,] -3.6038e-12
## [2,] -2.5381e-10
## 
## $jeval
## [1] 8
## 
## $feval
## [1] 9
## 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;
## attr(,&quot;class&quot;)
## [1] &quot;summary.nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(Pur.wnlfb)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  12.272  on  12 observations
##     after  8    Jacobian and  9 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## Vm               209.597         9.006      23.27  4.854e-10  -3.604e-12       210.3  
## K              0.0606538      0.008392      7.228  2.832e-05  -2.538e-10       0.123</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## check estimates with nls() result
<span class="kw">coef</span>(Pur.wnls) <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(Pur.wnlfb)</code></pre></div>
<pre><code>##          Vm           K 
## -2.1161e-05 -2.5341e-08 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## and with nlxb result
<span class="kw">coef</span>(Pur.wnlxb) <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(Pur.wnlfb)</code></pre></div>
<pre><code>##          Vm           K 
## -2.4001e-07 -2.8479e-10 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wres0.MM &lt;-<span class="st"> </span><span class="cf">function</span>(prm, rate, conc) {
      Vm &lt;-<span class="st"> </span>prm[<span class="dv">1</span>]
      K &lt;-<span class="st"> </span>prm[<span class="dv">2</span>]
      pred &lt;-<span class="st"> </span>(Vm <span class="op">*</span><span class="st"> </span>conc)<span class="op">/</span>(K <span class="op">+</span><span class="st"> </span>conc)
    (rate <span class="op">-</span><span class="st"> </span>pred) <span class="co"># </span><span class="al">NOTE</span><span class="co">: NO weights</span>
}
Pur.wnlfb0 &lt;-<span class="st"> </span><span class="kw">nlfb</span>(<span class="dt">start=</span>stw,  <span class="dt">resfn=</span>wres0.MM, <span class="dt">rate =</span> Treated<span class="op">$</span>rate, <span class="dt">conc=</span>Treated<span class="op">$</span>conc, 
                  <span class="dt">weights=</span><span class="dv">1</span><span class="op">/</span>Treated<span class="op">$</span>rate, <span class="dt">trace=</span><span class="ot">FALSE</span>) <span class="co"># Note: explicit weights</span>
<span class="kw">summary</span>(Pur.wnlfb0)</code></pre></div>
<pre><code>## $residuals
##  [1] 4.8942 1.9935 2.2338 3.0936 1.6445 2.9040 1.7051 1.1761 1.5414 2.2079
## [11] 1.6449 1.1785
## 
## $sigma
## [1] 2.6317
## 
## $df
## [1]  2 10
## 
## $cov.unscaled
##           Vm           K
## Vm 70.607853 -3.5304e-02
## K  -0.035304  1.7652e-05
## 
## $param
##    Estimate Std. Error t value   Pr(&gt;|t|)
## Vm    200.0  22.114175   9.044 3.9605e-06
## K       0.1   0.011057   9.044 3.9606e-06
## 
## $resname
## [1] &quot;Pur.wnlfb0&quot;
## 
## $ssquares
## [1] 69.261
## 
## $nobs
## [1] 12
## 
## $ct
## [1] &quot; &quot; &quot; &quot;
## 
## $mt
## [1] &quot; &quot; &quot; &quot;
## 
## $Sd
## [1] 7.4995e+08 1.1901e-01
## 
## $gr
##            [,1]
## [1,]    3119894
## [2,] 6239784883
## 
## $jeval
## [1] 1
## 
## $feval
## [1] 14
## 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;
## attr(,&quot;class&quot;)
## [1] &quot;summary.nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(Pur.wnlfb0)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  69.261  on  12 observations
##     after  1    Jacobian and  14 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## Vm                   200         22.11      9.044  3.961e-06     3119894   749947494  
## K                    0.1       0.01106      9.044  3.961e-06    6.24e+09       0.119</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## check estimates with nls() result
<span class="kw">coef</span>(Pur.wnls) <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(Pur.wnlfb0)</code></pre></div>
<pre><code>##        Vm         K 
##  9.596792 -0.039346 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## and with nlxb result
<span class="kw">coef</span>(Pur.wnlxb) <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(Pur.wnlfb0)</code></pre></div>
<pre><code>##        Vm         K 
##  9.596813 -0.039346 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wss.MM &lt;-<span class="st"> </span><span class="cf">function</span>(prm, rate, conc) {
  ss &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">crossprod</span>(<span class="kw">wres.MM</span>(prm, rate, conc)))
}
<span class="kw">library</span>(optimr)
osol &lt;-<span class="st"> </span><span class="kw">optimr</span>(stw, <span class="dt">fn=</span>wss.MM, <span class="dt">gr=</span><span class="st">&quot;grnd&quot;</span>, <span class="dt">method=</span><span class="st">&quot;Nelder-Mead&quot;</span>, <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">trace=</span><span class="dv">0</span>), 
            <span class="dt">rate=</span>Treated<span class="op">$</span>rate, <span class="dt">conc=</span>Treated<span class="op">$</span>conc)
<span class="kw">print</span>(osol)</code></pre></div>
<pre><code>## $par
##         Vm          K 
## 209.596996   0.060653 
## 
## $value
## [1] 12.272
## 
## $counts
## function gradient 
##       69       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## difference from nlxb
osol<span class="op">$</span>par <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(Pur.wnlxb)</code></pre></div>
<pre><code>##          Vm           K 
##  1.8235e-04 -1.2139e-06 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
</div>
</div>
<div id="missing-capabilities" class="section level3">
<h3>Missing capabilities</h3>
<div id="multi-line-function-expressions" class="section level4">
<h4>Multi-line function expressions</h4>
<p>Multi-line functions present a challenge. This is in part because the chain rule may have to be applied backwards (last line first), but also because there may be structures that are not always differentiable, such as <em>if</em> statements.</p>
<p>Note that the functional approach to nonlinear least squares – accessible via function <code>nlfb</code> – does let us prepare residuals and Jacobians of complexity limited only by the capabilities of <strong>R</strong>.</p>
</div>
<div id="automatic-differentiation" class="section level4">
<h4>Automatic differentiation</h4>
<p>This is the natural extension of Multi-line expressions. The authors would welcome collaboration with someone who has expertise in this area.</p>
</div>
<div id="vector-parameters" class="section level4">
<h4>Vector parameters</h4>
<p>We would like to be able to find the Jacobian or gradient of functions that have as their parameters a vector, e.g., <em>prm</em>. At time of writing (January 2015) we cannot specify such a vector within <strong>nlsr</strong>. ?? is this true?</p>
</div>
<div id="examples-of-capabilities-and-weaknesses" class="section level4">
<h4>Examples of capabilities and weaknesses</h4>
<p>The following (rather long) script shows things that work or fail. In particular, it shows that the calls needed to get derivatives need to be set up precisely. This is not unique to R – the same sort of attention to (syntax specific) detail is present in other systems like Macsyma/Maxima.</p>
<p>First we set up the Hobbs weed problem. Initially it seemed a good idea to put the data WITHIN the residual function so that it would not have to be passed to the function. In retrospect, this is a bad idea because y and t are needed. To make the use of the data explicit, it is saved in the variables <code>tdat</code> for time and <code>ydat</code> for the weed data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># tryhobbsderiv.R</span>
ydat&lt;-<span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>,
       <span class="fl">75.995</span>, <span class="fl">91.972</span>)
tdat&lt;-<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>
<span class="co"># try setting t and y here</span>
t &lt;-<span class="st"> </span>tdat
y &lt;-<span class="st"> </span>ydat
<span class="co"># now define a function</span>

hobbs.res&lt;-<span class="cf">function</span>(x, t, y){ <span class="co"># Hobbs weeds problem -- residual</span>
  <span class="co"># This variant uses looping</span>
<span class="co">#  if(length(x) != 3) stop(&quot;hobbs.res -- parameter vector n!=3&quot;)</span>
<span class="co">#  if(abs(12*x[3])&gt;50) {</span>
<span class="co">#    res&lt;-rep(Inf,12)</span>
<span class="co">#  } else {</span>
    res&lt;-x[<span class="dv">1</span>]<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>x[<span class="dv">2</span>]<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x[<span class="dv">3</span>]<span class="op">*</span>t)) <span class="op">-</span><span class="st"> </span>y
<span class="co">#  }</span>
}
<span class="co"># test it</span>
start1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">200</span>, <span class="dv">50</span>, .<span class="dv">3</span>)
## residuals at start1
r1 &lt;-<span class="st"> </span><span class="kw">hobbs.res</span>(start1, <span class="dt">t=</span>tdat, <span class="dt">y=</span>ydat)
<span class="kw">print</span>(r1)</code></pre></div>
<pre><code>##  [1] -0.050502 -0.207795 -0.260868 -0.412475 -0.616907 -1.605254 -3.364239
##  [8] -2.430165 -4.287340 -5.630791 -5.675428 -7.447795</code></pre>
<p>Now we try some of the derivative capabilities of <code>nlsr</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## <span class="al">NOTE</span>: some functions may be seemingly correct for R, but we do not
## get the result desired, despite no obvious error. Always test.
<span class="kw">require</span>(nlsr)
<span class="co"># Try directly to differentiate the residual vector. r1 is numeric, so this should</span>
<span class="co"># return a vector of zeros in a mathematical sense. In fact it gives an error, </span>
<span class="co"># since R does not want to differentiate a numeric vector.</span>
Jr1a &lt;-<span class="st"> </span><span class="kw">fnDeriv</span>(r1, <span class="st">&quot;x&quot;</span>)</code></pre></div>
<pre><code>## Error in codeDeriv(expr, namevec, do_substitute = FALSE, verbose = verbose, : Only single expressions allowed</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up a function containing expression with subscripted parameters x[]</span>
hobbs1 &lt;-<span class="st"> </span><span class="cf">function</span>(x, t, y){ res&lt;-x[<span class="dv">1</span>]<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>x[<span class="dv">2</span>]<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x[<span class="dv">3</span>]<span class="op">*</span>t)) <span class="op">-</span><span class="st"> </span>y }
<span class="co"># test the residuals</span>
<span class="kw">print</span>(<span class="kw">hobbs1</span>(start1, <span class="dt">t=</span>tdat, <span class="dt">y=</span>ydat))</code></pre></div>
<pre><code>##  [1] -0.050502 -0.207795 -0.260868 -0.412475 -0.616907 -1.605254 -3.364239
##  [8] -2.430165 -4.287340 -5.630791 -5.675428 -7.447795</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Alternatively, let us set up t and y</span>
y&lt;-<span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>,
       <span class="fl">75.995</span>, <span class="fl">91.972</span>)
t&lt;-<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>
<span class="co"># try different calls. Note that we need to include t and y data somehow</span>
<span class="kw">print</span>(<span class="kw">hobbs1</span>(start1))</code></pre></div>
<pre><code>## Error in hobbs1(start1): argument &quot;t&quot; is missing, with no default</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">hobbs1</span>(start1, t, y))</code></pre></div>
<pre><code>##  [1] -0.050502 -0.207795 -0.260868 -0.412475 -0.616907 -1.605254 -3.364239
##  [8] -2.430165 -4.287340 -5.630791 -5.675428 -7.447795</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">hobbs1</span>(start1, tdat, ydat))</code></pre></div>
<pre><code>##  [1] -0.050502 -0.207795 -0.260868 -0.412475 -0.616907 -1.605254 -3.364239
##  [8] -2.430165 -4.287340 -5.630791 -5.675428 -7.447795</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># We remove t and y, to ensure we don't get results from their presence</span>
<span class="kw">rm</span>(t)
<span class="kw">rm</span>(y)
<span class="co"># Set up a function containing an expression with named (with numbers) parameters </span>
<span class="co"># Note that we need to link these to the values in x</span>
hobbs1m &lt;-<span class="st"> </span><span class="cf">function</span>(x, t, y){
  x001 &lt;-<span class="st"> </span>x[<span class="dv">1</span>]
  x002 &lt;-<span class="st"> </span>x[<span class="dv">2</span>]
  x003 &lt;-<span class="st"> </span>x[<span class="dv">3</span>]
  res&lt;-x001<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>x002<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x003<span class="op">*</span>t)) <span class="op">-</span><span class="st"> </span>y 
}
<span class="kw">print</span>(<span class="kw">hobbs1m</span>(<span class="dt">x=</span>start1, <span class="dt">t=</span>tdat, <span class="dt">y=</span>ydat))</code></pre></div>
<pre><code>##  [1] -0.050502 -0.207795 -0.260868 -0.412475 -0.616907 -1.605254 -3.364239
##  [8] -2.430165 -4.287340 -5.630791 -5.675428 -7.447795</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Function with explicit use of the expression() </span>
hobbs1me &lt;-<span class="st"> </span><span class="cf">function</span>(x, t, y){
  x001 &lt;-<span class="st"> </span>x[<span class="dv">1</span>]
  x002 &lt;-<span class="st"> </span>x[<span class="dv">2</span>]
  x003 &lt;-<span class="st"> </span>x[<span class="dv">3</span>]
  <span class="kw">expression</span>(x001<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>x002<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x003<span class="op">*</span>t)) <span class="op">-</span><span class="st"> </span>y) 
}
<span class="kw">print</span>(<span class="kw">hobbs1me</span>(start1, <span class="dt">t=</span>tdat, <span class="dt">y=</span>ydat))</code></pre></div>
<pre><code>## expression(x001/(1 + x002 * exp(-x003 * t)) - y)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># note failure (because the expression is not evaluated?)</span>
<span class="co">#</span>
<span class="co"># Now try to take derivatives</span>
Jr11m &lt;-<span class="st"> </span><span class="kw">fnDeriv</span>(hobbs1m, <span class="kw">c</span>(<span class="st">&quot;x001&quot;</span>, <span class="st">&quot;x002&quot;</span>, <span class="st">&quot;x003&quot;</span>))</code></pre></div>
<pre><code>## Error in as.vector(x, &quot;expression&quot;): cannot coerce type 'closure' to vector of type 'expression'</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fails because expression is INSIDE a function (i.e., closure)</span>
<span class="co">#</span>
<span class="co"># try directly differentiating the expression</span>
Jr11ex &lt;-<span class="kw">fnDeriv</span>(<span class="kw">expression</span>(x001<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>x002<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x003<span class="op">*</span>t)) <span class="op">-</span><span class="st"> </span>y)
                  , <span class="kw">c</span>(<span class="st">&quot;x001&quot;</span>, <span class="st">&quot;x002&quot;</span>, <span class="st">&quot;x003&quot;</span>))
<span class="co"># this seems to &quot;work&quot;. Let us display the result</span>
Jr11ex</code></pre></div>
<pre><code>## function (x001, x002, x003, t, y) 
## {
##     .expr1 &lt;- -x003
##     .expr2 &lt;- .expr1 * t
##     .expr3 &lt;- exp(.expr2)
##     .expr4 &lt;- x002 * .expr3
##     .expr5 &lt;- 1 + .expr4
##     .expr6 &lt;- .expr5^2
##     .value &lt;- x001/(.expr5) - y
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;x001&quot;, 
##     &quot;x002&quot;, &quot;x003&quot;)))
##     .grad[, &quot;x001&quot;] &lt;- 1/.expr5
##     .grad[, &quot;x002&quot;] &lt;- -(x001 * .expr3/.expr6)
##     .grad[, &quot;x003&quot;] &lt;- -(x001 * (x002 * (.expr3 * -t))/.expr6)
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## }</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set the values of the parameters by name</span>
x001 &lt;-<span class="st"> </span>start1[<span class="dv">1</span>]
x002 &lt;-<span class="st"> </span>start1[<span class="dv">2</span>]
x003 &lt;-<span class="st"> </span>start1[<span class="dv">3</span>]
<span class="co"># and try to evaluate</span>
<span class="kw">print</span>(<span class="kw">eval</span>(Jr11ex))</code></pre></div>
<pre><code>## function (x001, x002, x003, t, y) 
## {
##     .expr1 &lt;- -x003
##     .expr2 &lt;- .expr1 * t
##     .expr3 &lt;- exp(.expr2)
##     .expr4 &lt;- x002 * .expr3
##     .expr5 &lt;- 1 + .expr4
##     .expr6 &lt;- .expr5^2
##     .value &lt;- x001/(.expr5) - y
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;x001&quot;, 
##     &quot;x002&quot;, &quot;x003&quot;)))
##     .grad[, &quot;x001&quot;] &lt;- 1/.expr5
##     .grad[, &quot;x002&quot;] &lt;- -(x001 * .expr3/.expr6)
##     .grad[, &quot;x003&quot;] &lt;- -(x001 * (x002 * (.expr3 * -t))/.expr6)
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## }</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># we need t and y, so set them</span>
t&lt;-tdat
y&lt;-ydat
<span class="kw">print</span>(<span class="kw">eval</span>(Jr11ex))</code></pre></div>
<pre><code>## function (x001, x002, x003, t, y) 
## {
##     .expr1 &lt;- -x003
##     .expr2 &lt;- .expr1 * t
##     .expr3 &lt;- exp(.expr2)
##     .expr4 &lt;- x002 * .expr3
##     .expr5 &lt;- 1 + .expr4
##     .expr6 &lt;- .expr5^2
##     .value &lt;- x001/(.expr5) - y
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;x001&quot;, 
##     &quot;x002&quot;, &quot;x003&quot;)))
##     .grad[, &quot;x001&quot;] &lt;- 1/.expr5
##     .grad[, &quot;x002&quot;] &lt;- -(x001 * .expr3/.expr6)
##     .grad[, &quot;x003&quot;] &lt;- -(x001 * (x002 * (.expr3 * -t))/.expr6)
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## }</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># But there is still a problem. WHY???</span>
<span class="co">#</span>
<span class="co"># Let us try it piece by piece (column by column)</span>
resx &lt;-<span class="st"> </span><span class="kw">expression</span>(x001<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>x002<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x003<span class="op">*</span>t)) <span class="op">-</span><span class="st"> </span>y)
res1 &lt;-<span class="st"> </span><span class="kw">Deriv</span>(resx, <span class="st">&quot;x001&quot;</span>, <span class="dt">do_substitute=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Error in Deriv(resx, &quot;x001&quot;, do_substitute = FALSE): unused argument (do_substitute = FALSE)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res1</code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object 'res1' not found</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">col1 &lt;-<span class="st"> </span><span class="kw">eval</span>(res1)</code></pre></div>
<pre><code>## Error in eval(res1): object 'res1' not found</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res2 &lt;-<span class="st"> </span><span class="kw">Deriv</span>(resx, <span class="st">&quot;x002&quot;</span>, <span class="dt">do_substitute=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Error in Deriv(resx, &quot;x002&quot;, do_substitute = FALSE): unused argument (do_substitute = FALSE)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res2</code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object 'res2' not found</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">col2 &lt;-<span class="st"> </span><span class="kw">eval</span>(res2)</code></pre></div>
<pre><code>## Error in eval(res2): object 'res2' not found</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res3 &lt;-<span class="st"> </span><span class="kw">Deriv</span>(resx, <span class="st">&quot;x003&quot;</span>, <span class="dt">do_substitute=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Error in Deriv(resx, &quot;x003&quot;, do_substitute = FALSE): unused argument (do_substitute = FALSE)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res3</code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object 'res3' not found</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">col3 &lt;-<span class="st"> </span><span class="kw">eval</span>(res3)</code></pre></div>
<pre><code>## Error in eval(res3): object 'res3' not found</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hobJac &lt;-<span class="st"> </span><span class="kw">cbind</span>(col1, col2, col3)</code></pre></div>
<pre><code>## Error in cbind(col1, col2, col3): object 'col1' not found</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(hobJac)</code></pre></div>
<pre><code>## Error in print(hobJac): object 'hobJac' not found</code></pre>
<p>Clearly there is still some work to do to make the mechanism for getting derivatives more easily, and with less chance of error. Work still to do???.</p>
</div>
</div>
<div id="jacobians" class="section level3">
<h3>Jacobians</h3>
<p>Jacobians, the matrices of partial derivatives of residuals with respect to the parameters, have a vector input (the parameters). <code>nlsr</code> attempts to generate the code for this computation. <strong>This is the first key improvement of <code>nlsr</code> over <code>nls()</code>.</strong> It will likely be a continuing effort to enlarge the set of functions and expressions that can be handled and to deal with them more efficiently. Also it would be nice to automate the generation of numerical approximations for those components of the Jacobian for which analytic derivatives are not available.</p>
<p>Note that the Jacobian inner product (J^T J) differs from the Hessian of the sum of squares by a matrix whose elements that are an inner product of the residuals with their second derivatives with respect to the parameters. This is a summation of m matrices each involving a residual times its (n by n) partial derivatives with respect to the parameters. Generally we treat this matrix as “ignorable” on the basis that the residuals should be “small”, but clearly this is not always the case.</p>
</div>
</div>
<div id="implementation-of-nonlinear-least-squares-methods" class="section level2">
<h2>Implementation of nonlinear least squares methods</h2>
<div id="gauss-newton-variants" class="section level3">
<h3>Gauss-Newton variants</h3>
<p>Nonlinear least squares methods are mostly founded on some or other variant of the Gauss-Newton algorithm. The function we wish to minimize is the sum of squares of the (nonlinear) residuals r(x) where there are m observations (elements of r) and n parameters x. Hence the function is</p>
<pre><code>f(x) = sum(r(k)^2)</code></pre>
<p>Newton’s method starts with an original set of parameters x[0]. At a given iteraion, which could be the first, we want to solve</p>
<pre><code>x[k+1]  =  x[k]  -   H^(-1) g</code></pre>
<p>where H is the Hessian and g is the gradient at x[k]. We can rewrite this as a solution, at each iteration, of</p>
<pre><code>H delta = -g</code></pre>
<p>with</p>
<pre><code>x[k+1]  =  x[k] + delta
     </code></pre>
<p>For the particular sum of squares, the gradient is</p>
<pre><code>g(x) = 2 * r(k)</code></pre>
<p>and</p>
<pre><code>H(x) = 2 ( J' J  +  sum(r * Z))</code></pre>
<p>where J is the Jacobian (first derivatives of r w.r.t. x) and Z is the tensor of second derivatives of r w.r.t. x). Note that J’ is the transpose of J.</p>
<p>The primary simplification of the Gauss-Newton method is to assume that the second term above is negligible. As there is a common factor of 2 on each side of the Newton iteration after the simplification of the Hessian, the Gauss-Newton iteration equation is</p>
<pre><code>J' J  delta = - J' r
       </code></pre>
<p>This iteration frequently fails. The approximation of the Hessian by the Jacobian inner-product is one reason, but there is also the possibility that the sum of squares function is not “quadratic” enough that the unit step reduces it. <span class="citation">Hartley (1961)</span> introduced a line search along delta, while <span class="citation">Marquardt (1963)</span> suggested replacing J’ J with (J’ J + lambda * D) where D is a diagonal matrix intended to partially approximate the omitted portion of the Hessian.</p>
<p>Marquardt suggested D = I (a unit matrix) or D = (diagonal part of J’ J). The former approach, when lambda is large enough that the iteration is essentially</p>
<pre><code>delta = - g / lambda
  </code></pre>
<p>we get a version of the steepest descents algorithm. Using the diagonal of J’ J, we have a scaled version of this (see <a href="https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm">https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm</a>)</p>
<p><span class="citation">Nash (1977)</span> found that on low precision machines, it was common for diagonal elements of J’ J to underflow. A very small modification to solve</p>
<pre><code>(J' J + lambda * (D + phi * I)) * delta = - g</code></pre>
<p>where phi is a small number (phi = 1 seems to work quite well) ?? check??.</p>
<p>In jncnm79, the iteration equation was solved as stated. However, this involves forming the sum of squares and cross products of J, a process that loses some numerical precision. A better way to solve the linear equations is to apply the QR decomposition to the matrix J itself. However, we still need to incorporate the lambda * I or lambda * D adjustments. This is done by adding rows to J that are the square roots of the “pieces”. We add 1 row for each diagonal element of I and each diagonal element of D.</p>
<p>In each iteration, we reduce the lambda parameter before solution. If the resulting sum of squares is not reduced, lambda is increased, otherwise we move to the next iteration. Various authors (including the present one) have suggested different strategies for this. My current opinion is that a “quick” increase, say a factor of 10, and a “slow” decrease, say a factor of 0.2, work quite well. However, it is important to check that lambda has not got too small or underflowed before applying the increase factor. On the other hand, it is useful to be able to set lambda = 0 in the code so that a pure Gauss-Newton method can be evaluated with the program(s). The current code <code>nlfb()</code> uses the line</p>
<p><code>if (lamda&lt;1000*.Machine$double.eps) lamda&lt;-1000*.Machine$double.eps</code></p>
<p>to ensure we get an increase. To force a Gauss-Newton algorithm, the controls <code>laminc</code> and <code>lamdec</code> are set to 0.</p>
<p><strong>The Levenberg-Marquardt adjustment to the Gauss-Newton approach is the second major improvement of <code>nlsr</code> (and also its predecessor <code>nlmrt</code> and the package <code>minpack-lm</code>) over <code>nls()</code>.</strong></p>
</div>
<div id="termination-and-convergence-tests" class="section level3">
<h3>Termination and convergence tests</h3>
<p>The success of many optimization codes often depends on knowing when no more progress can be made. For the present codes, one simple procedure increases the damping parameter lamda whenever the sum of squares cannot be decreased, with termination when the parameters are not altered by the addition of delta. While this “works”, it does incur unnecessary computational effort.</p>
<p>A better approach is that of <span class="citation">Bates and Watts (1981)</span>. Their relative offset criterion considers the potential progress that could be made in reducing the current residuals to the initial sum of squares. This is a sensible and very effective strategy for most situations, but is dangerous where the problem has very small or zero residuals, as in the case of an interpolation problem or nonlinear equations.</p>
<p>To illustrate this for zero residual problems, let us set up a simple test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## test small resid case with roffset
tt &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">25</span>
ymod &lt;-<span class="st"> </span><span class="dv">10</span> <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="fl">0.01</span><span class="op">*</span>tt) <span class="op">+</span><span class="st"> </span><span class="dv">5</span>
n &lt;-<span class="st"> </span><span class="kw">length</span>(tt)
evec0 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)
evec1 &lt;-<span class="st"> </span><span class="fl">1e-4</span><span class="op">*</span><span class="kw">runif</span>(n, <span class="op">-</span>.<span class="dv">5</span>, .<span class="dv">5</span>)
evec2 &lt;-<span class="st">  </span><span class="fl">1e-1</span><span class="op">*</span><span class="kw">runif</span>(n, <span class="op">-</span>.<span class="dv">5</span>, .<span class="dv">5</span>)
y0 &lt;-<span class="st"> </span>ymod <span class="op">+</span><span class="st"> </span>evec0
y1 &lt;-<span class="st"> </span>ymod <span class="op">+</span><span class="st"> </span>evec1
y2 &lt;-<span class="st"> </span>ymod <span class="op">+</span><span class="st"> </span>evec2
mydata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(tt, y0, y1, y2)
st &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">aa=</span><span class="dv">1</span>, <span class="dt">bb=</span><span class="dv">1</span>, <span class="dt">cc=</span><span class="dv">1</span>)</code></pre></div>
<p>We provide three sizes of residuals here, but will only illustrate the consequences of zero residuals (the problem with y0). Let us run the nonlinear least squares problem to get the interpolating function, first with <code>nls()</code>, then with <code>nlxb()</code>. In the second case we have turned off the trace, as the approach “works” because we have taken care in the code to provide for problems with small residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nlsfit0 &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nls</span>(y0 <span class="op">~</span><span class="st"> </span>aa <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>bb<span class="op">*</span>tt) <span class="op">+</span><span class="st"> </span>cc, <span class="dt">start=</span>st, <span class="dt">data=</span>mydata, <span class="dt">trace=</span><span class="ot">TRUE</span>))</code></pre></div>
<pre><code>## 4092.5 :  1 1 1
## 2651.2 :   0.15468 -0.11928  2.57602
## 1690.9 :  -0.015565 -0.145348  5.764209
## 305.56 :  -0.16284  0.18151 10.40450
## 32.728 :   1.7376  3.4630 12.8469</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nlsfit0</code></pre></div>
<pre><code>## [1] &quot;Error in numericDeriv(form[[3L]], names(ind), env) : \n  Missing value or an infinity produced when evaluating the model\n&quot;
## attr(,&quot;class&quot;)
## [1] &quot;try-error&quot;
## attr(,&quot;condition&quot;)
## &lt;simpleError in numericDeriv(form[[3L]], names(ind), env): Missing value or an infinity produced when evaluating the model&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nlsr)
nlsrfit0 &lt;-<span class="st"> </span><span class="kw">try</span>(<span class="kw">nlxb</span>(y0 <span class="op">~</span><span class="st"> </span>aa <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>bb<span class="op">*</span>tt) <span class="op">+</span><span class="st"> </span>cc, <span class="dt">start=</span>st, <span class="dt">data=</span>mydata, <span class="dt">trace=</span><span class="ot">FALSE</span>))</code></pre></div>
<pre><code>## vn:[1] &quot;y0&quot; &quot;aa&quot; &quot;bb&quot; &quot;tt&quot; &quot;cc&quot;
## no weights</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nlsrfit0</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  1.5561e-10  on  25 observations
##     after  33    Jacobian and  44 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## aa               9.99927     0.0002277      43918  7.149e-89   3.423e-05       614.6  
## bb             0.0100008      2.61e-07      38321  1.435e-87   -0.005629       3.197  
## cc               5.00073      0.000229      21834  3.399e-82   4.054e-05    0.008235</code></pre>
<p>We can approximate what <code>nls()</code> is doing by running a simple Gauss-Newton method one step at a time. It is (or was at the time of writing) easier to do this in functional form with explicit derivatives. Note that we test these functions!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trf &lt;-<span class="st"> </span><span class="cf">function</span>(par, data) {
    tt &lt;-<span class="st"> </span>data[,<span class="st">&quot;tt&quot;</span>]
    res &lt;-<span class="st"> </span>par[<span class="st">&quot;aa&quot;</span>]<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>par[<span class="st">&quot;bb&quot;</span>]<span class="op">*</span>tt) <span class="op">+</span><span class="st"> </span>par[<span class="st">&quot;cc&quot;</span>] <span class="op">-</span><span class="st"> </span>y0
}
<span class="kw">print</span>(<span class="kw">trf</span>(st, <span class="dt">data=</span>mydata))</code></pre></div>
<pre><code>##  [1] -13.533 -13.667 -13.655 -13.590 -13.506 -13.415 -13.323 -13.231
##  [9] -13.139 -13.048 -12.958 -12.869 -12.781 -12.694 -12.607 -12.521
## [17] -12.437 -12.353 -12.270 -12.187 -12.106 -12.025 -11.945 -11.866
## [25] -11.788</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trj &lt;-<span class="st"> </span><span class="cf">function</span>(par, data) {
    tt &lt;-<span class="st"> </span>data[,<span class="st">&quot;tt&quot;</span>]
    m &lt;-<span class="st"> </span><span class="kw">dim</span>(data)[<span class="dv">1</span>]
    JJ &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>m, <span class="dt">ncol=</span><span class="dv">3</span>)
    JJ[,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>par[<span class="st">&quot;bb&quot;</span>]<span class="op">*</span>tt)
    JJ[,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="op">-</span><span class="st"> </span>tt <span class="op">*</span><span class="st"> </span>par[<span class="st">&quot;aa&quot;</span>] <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>par[<span class="st">&quot;bb&quot;</span>]<span class="op">*</span>tt)
    JJ[,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="dv">1</span>
    JJ
}
Ja &lt;-<span class="st"> </span><span class="kw">trj</span>(st, <span class="dt">data=</span>mydata)
<span class="kw">print</span>(Ja)</code></pre></div>
<pre><code>##             [,1]        [,2] [,3]
##  [1,] 3.6788e-01 -3.6788e-01    1
##  [2,] 1.3534e-01 -2.7067e-01    1
##  [3,] 4.9787e-02 -1.4936e-01    1
##  [4,] 1.8316e-02 -7.3263e-02    1
##  [5,] 6.7379e-03 -3.3690e-02    1
##  [6,] 2.4788e-03 -1.4873e-02    1
##  [7,] 9.1188e-04 -6.3832e-03    1
##  [8,] 3.3546e-04 -2.6837e-03    1
##  [9,] 1.2341e-04 -1.1107e-03    1
## [10,] 4.5400e-05 -4.5400e-04    1
## [11,] 1.6702e-05 -1.8372e-04    1
## [12,] 6.1442e-06 -7.3731e-05    1
## [13,] 2.2603e-06 -2.9384e-05    1
## [14,] 8.3153e-07 -1.1641e-05    1
## [15,] 3.0590e-07 -4.5885e-06    1
## [16,] 1.1254e-07 -1.8006e-06    1
## [17,] 4.1399e-08 -7.0379e-07    1
## [18,] 1.5230e-08 -2.7414e-07    1
## [19,] 5.6028e-09 -1.0645e-07    1
## [20,] 2.0612e-09 -4.1223e-08    1
## [21,] 7.5826e-10 -1.5923e-08    1
## [22,] 2.7895e-10 -6.1368e-09    1
## [23,] 1.0262e-10 -2.3602e-09    1
## [24,] 3.7751e-11 -9.0603e-10    1
## [25,] 1.3888e-11 -3.4720e-10    1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(numDeriv)
Jn &lt;-<span class="st"> </span><span class="kw">jacobian</span>(trf, st, <span class="dt">data=</span>mydata)
<span class="kw">print</span>(Jn)</code></pre></div>
<pre><code>##              [,1]        [,2] [,3]
##  [1,]  3.6788e-01 -3.6788e-01    1
##  [2,]  1.3534e-01 -2.7067e-01    1
##  [3,]  4.9787e-02 -1.4936e-01    1
##  [4,]  1.8316e-02 -7.3263e-02    1
##  [5,]  6.7379e-03 -3.3690e-02    1
##  [6,]  2.4788e-03 -1.4873e-02    1
##  [7,]  9.1188e-04 -6.3832e-03    1
##  [8,]  3.3546e-04 -2.6837e-03    1
##  [9,]  1.2341e-04 -1.1107e-03    1
## [10,]  4.5400e-05 -4.5400e-04    1
## [11,]  1.6702e-05 -1.8372e-04    1
## [12,]  6.1442e-06 -7.3731e-05    1
## [13,]  2.2603e-06 -2.9384e-05    1
## [14,]  8.3156e-07 -1.1641e-05    1
## [15,]  3.0599e-07 -4.5885e-06    1
## [16,]  1.1246e-07 -1.8006e-06    1
## [17,]  4.1441e-08 -7.0390e-07    1
## [18,]  1.5292e-08 -2.7413e-07    1
## [19,]  5.5106e-09 -1.0642e-07    1
## [20,]  2.0606e-09 -4.1195e-08    1
## [21,]  6.7789e-10 -1.5917e-08    1
## [22,]  2.8422e-10 -6.0949e-09    1
## [23,]  5.5252e-11 -2.3285e-09    1
## [24,] -1.5802e-11 -8.2053e-10    1
## [25,]  5.2006e-13 -3.5475e-10    1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">max</span>(<span class="kw">abs</span>(Jn<span class="op">-</span>Ja)))</code></pre></div>
<pre><code>## [1] 1.0583e-10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ssf &lt;-<span class="st"> </span><span class="cf">function</span>(par, data){
   rr &lt;-<span class="st"> </span><span class="kw">trf</span>(par, data)
   ss &lt;-<span class="st"> </span><span class="kw">crossprod</span>(rr)
}
<span class="kw">print</span>(<span class="kw">ssf</span>(st, <span class="dt">data=</span>mydata))</code></pre></div>
<pre><code>##        [,1]
## [1,] 4092.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(numDeriv)
<span class="kw">print</span>(<span class="kw">jacobian</span>(trf, st, <span class="dt">data=</span>mydata))</code></pre></div>
<pre><code>##              [,1]        [,2] [,3]
##  [1,]  3.6788e-01 -3.6788e-01    1
##  [2,]  1.3534e-01 -2.7067e-01    1
##  [3,]  4.9787e-02 -1.4936e-01    1
##  [4,]  1.8316e-02 -7.3263e-02    1
##  [5,]  6.7379e-03 -3.3690e-02    1
##  [6,]  2.4788e-03 -1.4873e-02    1
##  [7,]  9.1188e-04 -6.3832e-03    1
##  [8,]  3.3546e-04 -2.6837e-03    1
##  [9,]  1.2341e-04 -1.1107e-03    1
## [10,]  4.5400e-05 -4.5400e-04    1
## [11,]  1.6702e-05 -1.8372e-04    1
## [12,]  6.1442e-06 -7.3731e-05    1
## [13,]  2.2603e-06 -2.9384e-05    1
## [14,]  8.3156e-07 -1.1641e-05    1
## [15,]  3.0599e-07 -4.5885e-06    1
## [16,]  1.1246e-07 -1.8006e-06    1
## [17,]  4.1441e-08 -7.0390e-07    1
## [18,]  1.5292e-08 -2.7413e-07    1
## [19,]  5.5106e-09 -1.0642e-07    1
## [20,]  2.0606e-09 -4.1195e-08    1
## [21,]  6.7789e-10 -1.5917e-08    1
## [22,]  2.8422e-10 -6.0949e-09    1
## [23,]  5.5252e-11 -2.3285e-09    1
## [24,] -1.5802e-11 -8.2053e-10    1
## [25,]  5.2006e-13 -3.5475e-10    1</code></pre>
<p>The traditional way to implement a Gauss Newton method was to form the sum of squares and cross-products matrix at in traditional linear regression, using the Jacobian as the data matrix. The right hand side uses the inner product of the Jacobian with the negative residuals. This approach increases the condition number of the problem, and a more direct QR decomposition of the Jacobian is now the preferred approach. However, let us try both to ensure we are getting similar answers. First the QR approach.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gnjn &lt;-<span class="st"> </span><span class="cf">function</span>(start, resfn, <span class="dt">jacfn =</span> <span class="ot">NULL</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>, 
        <span class="dt">data=</span><span class="ot">NULL</span>, <span class="dt">control=</span><span class="kw">list</span>(), ...){
<span class="co"># simplified Gauss Newton</span>
   offset =<span class="st"> </span><span class="fl">1e6</span> <span class="co"># for no change in parms</span>
   stepred &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="co"># start with this as per nls()</span>
   par &lt;-<span class="st"> </span>start
   <span class="kw">cat</span>(<span class="st">&quot;starting parameters:&quot;</span>)
   <span class="kw">print</span>(par)
   res &lt;-<span class="st"> </span><span class="kw">resfn</span>(par, data, ...)
   ssbest &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">crossprod</span>(res))
   <span class="kw">cat</span>(<span class="st">&quot;initial ss=&quot;</span>,ssbest,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
   par0 &lt;-<span class="st"> </span>par
   kres &lt;-<span class="st"> </span><span class="dv">1</span>
   kjac &lt;-<span class="st"> </span><span class="dv">0</span>
   keepon &lt;-<span class="st"> </span><span class="ot">TRUE</span>
   <span class="cf">while</span> (keepon) {
      <span class="kw">cat</span>(<span class="st">&quot;kjac=&quot;</span>,kjac,<span class="st">&quot;  kres=&quot;</span>,kres,<span class="st">&quot;  SSbest now &quot;</span>, ssbest,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
      <span class="kw">print</span>(par)
      JJ &lt;-<span class="st"> </span><span class="kw">jacfn</span>(par, data, ...)
      kjac &lt;-<span class="st"> </span>kjac <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
      QJ &lt;-<span class="st"> </span><span class="kw">qr</span>(JJ)
      delta &lt;-<span class="st"> </span><span class="kw">qr.coef</span>(QJ, <span class="op">-</span>res)
      ss &lt;-<span class="st"> </span>ssbest <span class="op">+</span><span class="st"> </span>offset<span class="op">*</span>offset <span class="co"># force evaluation</span>
      step &lt;-<span class="st"> </span><span class="fl">1.0</span>
      <span class="cf">if</span> (<span class="kw">as.numeric</span>(<span class="kw">max</span>(par0<span class="op">+</span>delta)<span class="op">+</span>offset) <span class="op">!=</span><span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">max</span>(par0<span class="op">+</span>offset)) ) {
         <span class="cf">while</span> (ss <span class="op">&gt;</span><span class="st"> </span>ssbest) {
           par &lt;-<span class="st"> </span>par0<span class="op">+</span>delta <span class="op">*</span><span class="st"> </span>step
           res &lt;-<span class="st"> </span><span class="kw">resfn</span>(par, data, ...)
           ss &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">crossprod</span>(res))
           kres &lt;-<span class="st"> </span>kres <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
##           cat(&quot;step =&quot;, step,&quot;  ss=&quot;,ss,&quot;\n&quot;)
##           tmp &lt;- readline(&quot;continue&quot;)
           <span class="cf">if</span> (ss <span class="op">&gt;</span><span class="st"> </span>ssbest) {
              step &lt;-<span class="st"> </span>step <span class="op">*</span><span class="st"> </span>stepred
           } <span class="cf">else</span> {
              par0 &lt;-<span class="st"> </span>par
              ssbest &lt;-<span class="st"> </span>ss
           }
         } <span class="co"># end inner loop</span>
         <span class="cf">if</span> (kjac <span class="op">&gt;=</span><span class="st"> </span><span class="dv">4</span>)  { 
            keepon =<span class="st"> </span><span class="ot">FALSE</span>
            <span class="kw">cat</span>(<span class="st">&quot;artificial stop at kjac=4 -- we only want to check output&quot;</span>) 
         }
      } <span class="cf">else</span> { keepon &lt;-<span class="st"> </span><span class="ot">FALSE</span> <span class="co"># done }</span>
   } <span class="co"># end main iteration</span>
} <span class="co"># seems to need this</span>

} <span class="co"># end gnjne</span>

fitgnjn0 &lt;-<span class="st"> </span><span class="kw">gnjn</span>(st, trf, trj, <span class="dt">data=</span>mydata)
## Another way
<span class="co">#- set lamda = 0 in nlxb, fix laminc, lamdec</span>
<span class="kw">library</span>(nlmrt)
nlx00 &lt;-<span class="st"> </span><span class="kw">try</span>(<span class="kw">nlxb</span>(y0 <span class="op">~</span><span class="st"> </span>aa <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>bb<span class="op">*</span>tt) <span class="op">+</span><span class="st"> </span>cc, <span class="dt">start=</span>st, <span class="dt">data=</span>mydata, <span class="dt">trace=</span><span class="ot">TRUE</span>,
                     <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">lamda=</span><span class="dv">0</span>, <span class="dt">laminc=</span><span class="dv">0</span>, <span class="dt">lamdec=</span><span class="dv">0</span>, <span class="dt">watch=</span><span class="ot">TRUE</span>)))
nlx00</code></pre></div>
<p>The first iteration more or less matches the <code>nls()</code> result. The problem is quite ill-conditioned, and <code>nls()</code> is using a numerical approximation to the Jacobian, so deviations of this magnitude from the iterations are not unexpected.</p>
<p>Let us test with a traditional Gauss-Newton.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gnjn2 &lt;-<span class="st"> </span><span class="cf">function</span>(start, resfn, <span class="dt">jacfn =</span> <span class="ot">NULL</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>, 
        <span class="dt">data=</span><span class="ot">NULL</span>, <span class="dt">control=</span><span class="kw">list</span>(), ...){
<span class="co"># simplified Gauss Newton</span>
   offset =<span class="st"> </span><span class="fl">1e6</span> <span class="co"># for no change in parms</span>
   stepred &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="co"># start with this as per nls()</span>
   par &lt;-<span class="st"> </span>start
   <span class="kw">cat</span>(<span class="st">&quot;starting parameters:&quot;</span>)
   <span class="kw">print</span>(par)
   res &lt;-<span class="st"> </span><span class="kw">resfn</span>(par, data, ...)
   ssbest &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">crossprod</span>(res))
   <span class="kw">cat</span>(<span class="st">&quot;initial ss=&quot;</span>,ssbest,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
   kres &lt;-<span class="st"> </span><span class="dv">1</span>
   kjac &lt;-<span class="st"> </span><span class="dv">0</span>
   par0 &lt;-<span class="st"> </span>par
   keepon &lt;-<span class="st"> </span><span class="ot">TRUE</span>
   <span class="cf">while</span> (keepon) {
      <span class="kw">cat</span>(<span class="st">&quot;kres=&quot;</span>,kres,<span class="st">&quot;  kjac=&quot;</span>,kjac,<span class="st">&quot;   SSbest now &quot;</span>, ssbest,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
      <span class="kw">print</span>(par)
      JJ &lt;-<span class="st"> </span><span class="kw">jacfn</span>(par, data, ...)
      kjac &lt;-<span class="st"> </span>kjac <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
      JTJ &lt;-<span class="st"> </span><span class="kw">crossprod</span> (JJ)
      JTr &lt;-<span class="st"> </span><span class="kw">crossprod</span> (JJ, res)
      delta &lt;-<span class="st"> </span><span class="op">-</span><span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">solve</span>(JTJ, JTr))
      ss &lt;-<span class="st"> </span>ssbest <span class="op">+</span><span class="st"> </span>offset<span class="op">*</span>offset <span class="co"># force evaluation</span>
      step &lt;-<span class="st"> </span><span class="fl">1.0</span>
      <span class="cf">if</span> (<span class="kw">as.numeric</span>(<span class="kw">max</span>(par0<span class="op">+</span>delta)<span class="op">+</span>offset) <span class="op">!=</span><span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">max</span>(par0<span class="op">+</span>offset)) ) {
         <span class="cf">while</span> (ss <span class="op">&gt;</span><span class="st"> </span>ssbest) {
           par &lt;-<span class="st"> </span>par0<span class="op">+</span>delta <span class="op">*</span><span class="st"> </span>step
           res &lt;-<span class="st"> </span><span class="kw">resfn</span>(par, data, ...)
           ss &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">crossprod</span>(res))
           kres &lt;-<span class="st"> </span>kres <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
##           cat(&quot;step =&quot;, step,&quot;  ss=&quot;,ss,&quot;  best is&quot;,ssbest,&quot;\n&quot;)
##           tmp &lt;- readline(&quot;continue&quot;)
           <span class="cf">if</span> (ss <span class="op">&gt;</span><span class="st"> </span>ssbest) {
              step &lt;-<span class="st"> </span>step <span class="op">*</span><span class="st"> </span>stepred
           } <span class="cf">else</span> {
              par0 &lt;-<span class="st"> </span>par
              ssbest &lt;-<span class="st"> </span>ss
           }
         } <span class="co"># end inner loop</span>
         <span class="cf">if</span> (kjac <span class="op">&gt;=</span><span class="st"> </span><span class="dv">4</span>)  { 
            keepon =<span class="st"> </span><span class="ot">FALSE</span>
            <span class="kw">cat</span>(<span class="st">&quot;artificial stop at kjac=4 -- we only want to check output&quot;</span>) 
         }
      } <span class="cf">else</span> { keepon &lt;-<span class="st"> </span><span class="ot">FALSE</span> <span class="co"># done }</span>
   } <span class="co"># end main iteration</span>
} <span class="co"># seems to need this</span>
} <span class="co"># end gnjn2</span>

fitgnjn20 &lt;-<span class="st"> </span><span class="kw">gnjn2</span>(st, trf, trj, <span class="dt">data=</span>mydata)</code></pre></div>
</div>
<div id="nonlinear-equations" class="section level3">
<h3>Nonlinear equations</h3>
<p>Solution of sets of nonlinear equations is generally NOT a problem that is commonly required for statisticians or data analysts. My experience is that the occasions where it does arise are when workers try to solve the first order conditions for optimality of a function, rather than try to optimize the function. If this function is a sum of squares, then we have a nonlinear least squares problem, and generally such problems are best approached my methods of the type discussed in this article.</p>
<p>Conversely, since our problem is, using the notation above, equivalent to</p>
<p>r(x) = 0</p>
<p>the solution of a nonlinear least squares problem for which the final sum of squares is zero provides a solution to the nonlinear equations. In my experience this is a valid approach to the nonlinear equations problem, especially if there is concern that a solution may not exist. Note that there are methods for nonlinear equations, some of which (??ref) are available in R packages.</p>
</div>
</div>
<div id="function-versus-expression-approach" class="section level2">
<h2>Function versus expression approach</h2>
<p>In <code>nlsr</code>, we provide for modelling via R functions that generate the residuals and Jacobian, and we call the nonlinear least squares minimizer through <code>nlfb</code>. Alternatively, we can do the modelling via the <code>nlxb</code> function that takes a model expression as an argument and converts it to the functional form. The actual least squares minimization is then carried out by a common routine (<code>nlfb</code>). Generally <code>nlxb</code> is a lot less programming work, but it is also more limited, as we can only handle single line expressions, and some expressions may not be differentiable within the package, even if there are mathematically feasible ways to compute them analytically.</p>
</div>
<div id="providing-extra-data-to-expressions" class="section level2">
<h2>Providing extra data to expressions</h2>
<p>Almost all statistical functions have exogenous data that is needed to compute residuals or likelihoods and is not dependent on the model parameters. (This section starts from Notes140806.)</p>
<p>model2rjfun does NOT have … args.</p>
<p>Should it have? i.e., a problem where we are fitting a set of time series, 1 for each plant/animal, with some sort of start parameter for each that is NOT estimated (e.g., pH of soil, some index of health).</p>
<p>Difficulty in such a problem is that the residuals are then a matrix, and the nlfb rather than nlxb is a better approach. However, fitting 1 series would still need this data, and example nlsrtryextraparms.txt shows that the extra parm (ms in this case) needs to be in the user’s globalenv.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rm</span>(<span class="dt">list=</span><span class="kw">ls</span>())
<span class="kw">require</span>(nlsr)
<span class="co"># want to have data AND extra parameters (NOT to be estimated)</span>
traceval  &lt;-<span class="st">  </span><span class="ot">TRUE</span>  <span class="co"># traceval set TRUE to debug or give full history</span>
<span class="co"># Data for Hobbs problem</span>
ydat  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, 
          <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>) <span class="co"># for testing</span>
tdat  &lt;-<span class="st">  </span><span class="kw">seq_along</span>(ydat) <span class="co"># for testing</span>
<span class="co"># A simple starting vector -- must have named parameters for nlxb, nls, wrapnlsr.</span>
start1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span><span class="dv">1</span>)
startf1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span>.<span class="dv">1</span>)
eunsc  &lt;-<span class="st">   </span>y <span class="op">~</span><span class="st"> </span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>b3<span class="op">*</span>tt))
<span class="kw">cat</span>(<span class="st">&quot;LOCAL DATA IN DATA FRAMES</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## LOCAL DATA IN DATA FRAMES</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weeddata1  &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">y=</span>ydat, <span class="dt">tt=</span>tdat)
<span class="kw">cat</span>(<span class="st">&quot;weeddata contains the original data</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## weeddata contains the original data</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ms &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># define the external parameter here</span>
<span class="kw">cat</span>(<span class="st">&quot;wdata scales y by ms =&quot;</span>,ms,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## wdata scales y by ms = 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wdata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y=</span>ydat<span class="op">/</span>ms, <span class="dt">tt=</span>tdat)
wdata</code></pre></div>
<pre><code>##          y tt
## 1   2.6540  1
## 2   3.6200  2
## 3   4.8190  3
## 4   6.4330  4
## 5   8.5345  5
## 6  11.5960  6
## 7  15.7215  7
## 8  19.2790  8
## 9  25.0780  9
## 10 31.4740 10
## 11 37.9975 11
## 12 45.9860 12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cat</span>(<span class="st">&quot;estimate the UNSCALED model with SCALED data</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## estimate the UNSCALED model with SCALED data</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">anlxbs  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(eunsc, <span class="dt">start=</span>start1, <span class="dt">trace=</span>traceval, <span class="dt">data=</span>wdata))</code></pre></div>
<pre><code>## formula: y ~ b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;tt&quot;
## Data variable  y : [1]  2.6540  3.6200  4.8190  6.4330  8.5345 11.5960 15.7215 19.2790
##  [9] 25.0780 31.4740 37.9975 45.9860
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x5376668&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 5676.9  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 6088.9  at  b1 = 25.443  b2 = -119.86  b3 = -185.95  2 / 1
## lamda: 0.01  SS= 6088.9  at  b1 = 25.092  b2 = -94.85  b3 = -166.61  3 / 1
## lamda: 0.1  SS= 6088.9  at  b1 = 23.492  b2 = -12.164  b3 = -96.948  4 / 1
## lamda: 1  SS= 6088.9  at  b1 = 19.105  b2 = 15.514  b3 = -31.768  5 / 1
## lamda: 10  SS= 6078  at  b1 = 9.6639  b2 = 2.3414  b3 = -1.0745  6 / 1
## &lt;&lt;lamda: 4  SS= 5096.5  at  b1 = 2.5089  b2 = 0.94659  b3 = 1.1409  7 / 1
## &lt;&lt;lamda: 1.6  SS= 4086.7  at  b1 = 5.5395  b2 = 1.1277  b3 = 0.98661  8 / 2
## lamda: 16  SS= 5979.2  at  b1 = 10.709  b2 = 2.4361  b3 = -0.35798  9 / 3
## &lt;&lt;lamda: 6.4  SS= 3871.1  at  b1 = 6.2757  b2 = 1.195  b3 = 0.95044  10 / 3
## &lt;&lt;lamda: 2.56  SS= 3427.1  at  b1 = 7.914  b2 = 1.4621  b3 = 0.76952  11 / 4
## &lt;&lt;lamda: 1.024  SS= 2714  at  b1 = 11.243  b2 = 2.2923  b3 = 0.41244  12 / 5
## &lt;&lt;lamda: 0.4096  SS= 1624.3  at  b1 = 17.581  b2 = 3.9784  b3 = 0.51333  13 / 6
## &lt;&lt;lamda: 0.16384  SS= 1596  at  b1 = 25.778  b2 = 7.8443  b3 = 0.25361  14 / 7
## &lt;&lt;lamda: 0.065536  SS= 389.99  at  b1 = 36.58  b2 = 11.353  b3 = 0.40144  15 / 8
## &lt;&lt;lamda: 0.026214  SS= 227.36  at  b1 = 47.307  b2 = 19.475  b3 = 0.32531  16 / 9
## &lt;&lt;lamda: 0.010486  SS= 30.768  at  b1 = 61.38  b2 = 30.701  b3 = 0.35494  17 / 10
## &lt;&lt;lamda: 0.0041943  SS= 7.5356  at  b1 = 71.376  b2 = 39.434  b3 = 0.3436  18 / 11
## &lt;&lt;lamda: 0.0016777  SS= 2.4081  at  b1 = 80.801  b2 = 44.729  b3 = 0.33443  19 / 12
## &lt;&lt;lamda: 0.00067109  SS= 1.1886  at  b1 = 88.884  b2 = 47.007  b3 = 0.32377  20 / 13
## &lt;&lt;lamda: 0.00026844  SS= 0.72638  at  b1 = 94.691  b2 = 48.297  b3 = 0.31699  21 / 14
## &lt;&lt;lamda: 0.00010737  SS= 0.6497  at  b1 = 97.378  b2 = 48.922  b3 = 0.31428  22 / 15
## &lt;&lt;lamda: 4.295e-05  SS= 0.64684  at  b1 = 98.022  b2 = 49.075  b3 = 0.31364  23 / 16
## &lt;&lt;lamda: 1.718e-05  SS= 0.64682  at  b1 = 98.09  b2 = 49.091  b3 = 0.31357  24 / 17
## &lt;&lt;lamda: 6.8719e-06  SS= 0.64682  at  b1 = 98.093  b2 = 49.092  b3 = 0.31357  25 / 18</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(anlxbs)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  0.64682  on  12 observations
##     after  18    Jacobian and  25 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               98.0931         5.653      17.35  3.164e-08  -1.337e-07       505.4  
## b2               49.0916         1.688      29.08  3.281e-10   3.017e-08      0.2344  
## b3               0.31357      0.006863      45.69  5.768e-12  -1.398e-05     0.04632</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">escal &lt;-<span class="st">  </span>y <span class="op">~</span><span class="st"> </span>ms<span class="op">*</span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>b3<span class="op">*</span>tt))
<span class="kw">cat</span>(<span class="st">&quot;estimate the SCALED model with scaling provided in the call (ms=0.5)</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## estimate the SCALED model with scaling provided in the call (ms=0.5)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">anlxbh  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(escal, <span class="dt">start=</span>start1, <span class="dt">trace=</span>traceval, <span class="dt">data=</span>weeddata1, <span class="dt">ms=</span><span class="fl">0.5</span>))
<span class="kw">print</span>(anlxbh)</code></pre></div>
<pre><code>## [1] &quot;Error in nlxb(escal, start = start1, trace = traceval, data = weeddata1,  : \n  unused argument (ms = 0.5)\n&quot;
## attr(,&quot;class&quot;)
## [1] &quot;try-error&quot;
## attr(,&quot;condition&quot;)
## &lt;simpleError in nlxb(escal, start = start1, trace = traceval, data = weeddata1,     ms = 0.5): unused argument (ms = 0.5)&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> scaling is now using the globally defined value of ms=&quot;</span>,ms,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## 
##  scaling is now using the globally defined value of ms= 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">anlxb1a  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(escal, <span class="dt">start=</span>start1, <span class="dt">trace=</span>traceval, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## formula: y ~ ms * b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;ms&quot; &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;ms&quot; &quot;tt&quot;
## Data variable  y : [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## Data variable  ms :[1] 2
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x498f4b8&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 22708  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 24356  at  b1 = 25.472  b2 = -122.14  b3 = -187.69  2 / 1
## lamda: 0.01  SS= 24356  at  b1 = 25.327  b2 = -113.2  b3 = -180.68  3 / 1
## lamda: 0.1  SS= 24356  at  b1 = 24.283  b2 = -57.588  b3 = -135.68  4 / 1
## lamda: 1  SS= 24356  at  b1 = 20.254  b2 = 14.461  b3 = -54.127  5 / 1
## lamda: 10  SS= 24355  at  b1 = 10.077  b2 = 4.8657  b3 = -4.5699  6 / 1
## &lt;&lt;lamda: 4  SS= 20252  at  b1 = 2.5977  b2 = 0.83113  b3 = 1.4117  7 / 1
## &lt;&lt;lamda: 1.6  SS= 16143  at  b1 = 5.7092  b2 = 1.3529  b3 = 0.86529  8 / 2
## lamda: 16  SS= 22536  at  b1 = 11.269  b2 = 3.0589  b3 = -0.12239  9 / 3
## &lt;&lt;lamda: 6.4  SS= 15214  at  b1 = 6.5093  b2 = 1.428  b3 = 0.86138  10 / 3
## &lt;&lt;lamda: 2.56  SS= 13336  at  b1 = 8.2714  b2 = 1.7659  b3 = 0.74306  11 / 4
## &lt;&lt;lamda: 1.024  SS= 10290  at  b1 = 11.801  b2 = 2.7987  b3 = 0.46561  12 / 5
## &lt;&lt;lamda: 0.4096  SS= 5999.3  at  b1 = 18.477  b2 = 4.9891  b3 = 0.46298  13 / 6
## &lt;&lt;lamda: 0.16384  SS= 3360.8  at  b1 = 27.609  b2 = 9.7076  b3 = 0.35379  14 / 7
## &lt;&lt;lamda: 0.065536  SS= 872.75  at  b1 = 40.302  b2 = 16.934  b3 = 0.38655  15 / 8
## &lt;&lt;lamda: 0.026214  SS= 308.99  at  b1 = 51.624  b2 = 26.628  b3 = 0.36281  16 / 9
## &lt;&lt;lamda: 0.010486  SS= 64.882  at  b1 = 63.651  b2 = 36.557  b3 = 0.35778  17 / 10
## &lt;&lt;lamda: 0.0041943  SS= 19.992  at  b1 = 73.76  b2 = 43.123  b3 = 0.3463  18 / 11
## &lt;&lt;lamda: 0.0016777  SS= 8.8066  at  b1 = 83.053  b2 = 46.013  b3 = 0.33222  19 / 12
## &lt;&lt;lamda: 0.00067109  SS= 4.1734  at  b1 = 91.086  b2 = 47.556  b3 = 0.32103  20 / 13
## &lt;&lt;lamda: 0.00026844  SS= 2.7218  at  b1 = 96.072  b2 = 48.622  b3 = 0.31554  21 / 14
## &lt;&lt;lamda: 0.00010737  SS= 2.5891  at  b1 = 97.8  b2 = 49.023  b3 = 0.31386  22 / 15
## &lt;&lt;lamda: 4.295e-05  SS= 2.5873  at  b1 = 98.074  b2 = 49.087  b3 = 0.31359  23 / 16
## &lt;&lt;lamda: 1.718e-05  SS= 2.5873  at  b1 = 98.093  b2 = 49.091  b3 = 0.31357  24 / 17</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(anlxb1a)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  17    Jacobian and  24 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               98.0925         5.651      17.36  3.153e-08  -9.046e-06        1011  
## b2               49.0915         1.688      29.09   3.27e-10   6.839e-06      0.4687  
## b3               0.31357      0.006863      45.69  5.769e-12   -0.003104     0.09268</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ms &lt;-<span class="st"> </span><span class="dv">1</span>
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> scaling is now using the globally re-defined value of ms=&quot;</span>,ms,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## 
##  scaling is now using the globally re-defined value of ms= 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">anlxb1b  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(escal, <span class="dt">start=</span>start1, <span class="dt">trace=</span>traceval, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## formula: y ~ ms * b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;ms&quot; &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;ms&quot; &quot;tt&quot;
## Data variable  y : [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## Data variable  ms :[1] 1
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x3530ac8&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 23521  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 24356  at  b1 = 50.886  b2 = -240.72  b3 = -372.91  2 / 1
## lamda: 0.01  SS= 24356  at  b1 = 50.183  b2 = -190.69  b3 = -334.2  3 / 1
## lamda: 0.1  SS= 24356  at  b1 = 46.97  b2 = -25.309  b3 = -194.81  4 / 1
## lamda: 1  SS= 24356  at  b1 = 38.096  b2 = 29.924  b3 = -64.262  5 / 1
## lamda: 10  SS= 24353  at  b1 = 18.798  b2 = 3.551  b3 = -2.9011  6 / 1
## &lt;&lt;lamda: 4  SS= 21065  at  b1 = 4.1015  b2 = 0.86688  b3 = 1.3297  7 / 1
## &lt;&lt;lamda: 1.6  SS= 16852  at  b1 = 10.248  b2 = 1.2302  b3 = 1.0044  8 / 2
## lamda: 16  SS= 24078  at  b1 = 20.944  b2 = 2.9473  b3 = -0.40959  9 / 3
## &lt;&lt;lamda: 6.4  SS= 15934  at  b1 = 11.771  b2 = 1.3084  b3 = 0.98087  10 / 3
## &lt;&lt;lamda: 2.56  SS= 14050  at  b1 = 15.152  b2 = 1.6468  b3 = 0.80462  11 / 4
## &lt;&lt;lamda: 1.024  SS= 10985  at  b1 = 22.005  b2 = 2.6632  b3 = 0.45111  12 / 5
## &lt;&lt;lamda: 0.4096  SS= 6427.1  at  b1 = 35.128  b2 = 4.7135  b3 = 0.50974  13 / 6
## &lt;&lt;lamda: 0.16384  SS= 4725  at  b1 = 52.285  b2 = 9.2948  b3 = 0.31348  14 / 7
## &lt;&lt;lamda: 0.065536  SS= 1132.2  at  b1 = 76.446  b2 = 15.142  b3 = 0.41095  15 / 8
## &lt;&lt;lamda: 0.026214  SS= 518.76  at  b1 = 96.924  b2 = 24.422  b3 = 0.35816  16 / 9
## &lt;&lt;lamda: 0.010486  SS= 79.464  at  b1 = 122.18  b2 = 35.262  b3 = 0.36484  17 / 10
## &lt;&lt;lamda: 0.0041943  SS= 26.387  at  b1 = 141.55  b2 = 42.387  b3 = 0.35215  18 / 11
## &lt;&lt;lamda: 0.0016777  SS= 11.339  at  b1 = 160.02  b2 = 45.519  b3 = 0.33738  19 / 12
## &lt;&lt;lamda: 0.00067109  SS= 5.2767  at  b1 = 176.92  b2 = 47.037  b3 = 0.32443  20 / 13
## &lt;&lt;lamda: 0.00026844  SS= 2.9656  at  b1 = 189.12  b2 = 48.279  b3 = 0.31712  21 / 14
## &lt;&lt;lamda: 0.00010737  SS= 2.6003  at  b1 = 194.72  b2 = 48.92  b3 = 0.31429  22 / 15
## &lt;&lt;lamda: 4.295e-05  SS= 2.5873  at  b1 = 196.04  b2 = 49.075  b3 = 0.31364  23 / 16
## &lt;&lt;lamda: 1.718e-05  SS= 2.5873  at  b1 = 196.18  b2 = 49.091  b3 = 0.31357  24 / 17
## &lt;&lt;lamda: 6.8719e-06  SS= 2.5873  at  b1 = 196.19  b2 = 49.092  b3 = 0.31357  25 / 18</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(anlxb1b)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  18    Jacobian and  25 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               196.186         11.31      17.35  3.164e-08  -2.663e-07        1011  
## b2               49.0916         1.688      29.08  3.281e-10    1.59e-07      0.4605  
## b3               0.31357      0.006863      45.69  5.768e-12  -5.531e-05     0.04715</code></pre>
</div>
<div id="examples-of-use" class="section level2">
<h2>Examples of use</h2>
<div id="nonlinear-least-squares-with-expressions" class="section level3">
<h3>Nonlinear least squares with expressions</h3>
<p>We use the Hobbs Weeds problem (Nash, 1979 and Nash, 2014). Note that nls() fails from start1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(nlsr)
traceval &lt;-<span class="st"> </span><span class="ot">FALSE</span>
<span class="co"># Data for Hobbs problem</span>
ydat  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, 
          <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>) <span class="co"># for testing</span>
tdat  &lt;-<span class="st">  </span><span class="kw">seq_along</span>(ydat) <span class="co"># for testing</span>

<span class="co"># A simple starting vector -- must have named parameters for nlxb, nls, wrapnlsr.</span>
start1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span><span class="dv">1</span>)

eunsc  &lt;-<span class="st">   </span>y <span class="op">~</span><span class="st"> </span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>b3<span class="op">*</span>tt))

<span class="kw">cat</span>(<span class="st">&quot;LOCAL DATA IN DATA FRAMES</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## LOCAL DATA IN DATA FRAMES</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weeddata1  &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">y=</span>ydat, <span class="dt">tt=</span>tdat)
weeddata2  &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">y=</span><span class="fl">1.5</span><span class="op">*</span>ydat, <span class="dt">tt=</span>tdat)

anlxb1  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(eunsc, <span class="dt">start=</span>start1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1,
                     <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">watch=</span><span class="ot">FALSE</span>)))</code></pre></div>
<pre><code>## formula: y ~ b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;tt&quot;
## Data variable  y : [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x53a5220&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 23521  at  b1 = 1  b2 = 1  b3 = 1  1 / 0
## lamda: 0.001  SS= 24356  at  b1 = 50.886  b2 = -240.72  b3 = -372.91  2 / 1
## lamda: 0.01  SS= 24356  at  b1 = 50.183  b2 = -190.69  b3 = -334.2  3 / 1
## lamda: 0.1  SS= 24356  at  b1 = 46.97  b2 = -25.309  b3 = -194.81  4 / 1
## lamda: 1  SS= 24356  at  b1 = 38.096  b2 = 29.924  b3 = -64.262  5 / 1
## lamda: 10  SS= 24353  at  b1 = 18.798  b2 = 3.551  b3 = -2.9011  6 / 1
## &lt;&lt;lamda: 4  SS= 21065  at  b1 = 4.1015  b2 = 0.86688  b3 = 1.3297  7 / 1
## &lt;&lt;lamda: 1.6  SS= 16852  at  b1 = 10.248  b2 = 1.2302  b3 = 1.0044  8 / 2
## lamda: 16  SS= 24078  at  b1 = 20.944  b2 = 2.9473  b3 = -0.40959  9 / 3
## &lt;&lt;lamda: 6.4  SS= 15934  at  b1 = 11.771  b2 = 1.3084  b3 = 0.98087  10 / 3
## &lt;&lt;lamda: 2.56  SS= 14050  at  b1 = 15.152  b2 = 1.6468  b3 = 0.80462  11 / 4
## &lt;&lt;lamda: 1.024  SS= 10985  at  b1 = 22.005  b2 = 2.6632  b3 = 0.45111  12 / 5
## &lt;&lt;lamda: 0.4096  SS= 6427.1  at  b1 = 35.128  b2 = 4.7135  b3 = 0.50974  13 / 6
## &lt;&lt;lamda: 0.16384  SS= 4725  at  b1 = 52.285  b2 = 9.2948  b3 = 0.31348  14 / 7
## &lt;&lt;lamda: 0.065536  SS= 1132.2  at  b1 = 76.446  b2 = 15.142  b3 = 0.41095  15 / 8
## &lt;&lt;lamda: 0.026214  SS= 518.76  at  b1 = 96.924  b2 = 24.422  b3 = 0.35816  16 / 9
## &lt;&lt;lamda: 0.010486  SS= 79.464  at  b1 = 122.18  b2 = 35.262  b3 = 0.36484  17 / 10
## &lt;&lt;lamda: 0.0041943  SS= 26.387  at  b1 = 141.55  b2 = 42.387  b3 = 0.35215  18 / 11
## &lt;&lt;lamda: 0.0016777  SS= 11.339  at  b1 = 160.02  b2 = 45.519  b3 = 0.33738  19 / 12
## &lt;&lt;lamda: 0.00067109  SS= 5.2767  at  b1 = 176.92  b2 = 47.037  b3 = 0.32443  20 / 13
## &lt;&lt;lamda: 0.00026844  SS= 2.9656  at  b1 = 189.12  b2 = 48.279  b3 = 0.31712  21 / 14
## &lt;&lt;lamda: 0.00010737  SS= 2.6003  at  b1 = 194.72  b2 = 48.92  b3 = 0.31429  22 / 15
## &lt;&lt;lamda: 4.295e-05  SS= 2.5873  at  b1 = 196.04  b2 = 49.075  b3 = 0.31364  23 / 16
## &lt;&lt;lamda: 1.718e-05  SS= 2.5873  at  b1 = 196.18  b2 = 49.091  b3 = 0.31357  24 / 17
## &lt;&lt;lamda: 6.8719e-06  SS= 2.5873  at  b1 = 196.19  b2 = 49.092  b3 = 0.31357  25 / 18</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(anlxb1)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  18    Jacobian and  25 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               196.186         11.31      17.35  3.164e-08  -2.663e-07        1011  
## b2               49.0916         1.688      29.08  3.281e-10    1.59e-07      0.4605  
## b3               0.31357      0.006863      45.69  5.768e-12  -5.531e-05     0.04715</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">anlsb1 &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nls</span>(eunsc, <span class="dt">start=</span>start1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## 23521 :  1 1 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(anlsb1)</code></pre></div>
<pre><code>## [1] &quot;Error in nls(eunsc, start = start1, trace = TRUE, data = weeddata1) : \n  singular gradient\n&quot;
## attr(,&quot;class&quot;)
## [1] &quot;try-error&quot;
## attr(,&quot;condition&quot;)
## &lt;simpleError in nls(eunsc, start = start1, trace = TRUE, data = weeddata1): singular gradient&gt;</code></pre>
<p>A different start causes nlxb to return a large sum of squares. Note that nls() again fails.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">startf1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span>.<span class="dv">1</span>)
anlsf1 &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nls</span>(eunsc, <span class="dt">start=</span>startf1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1))</code></pre></div>
<pre><code>## 23756 :  1.0 1.0 0.1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(anlsf1)</code></pre></div>
<pre><code>## [1] &quot;Error in nls(eunsc, start = startf1, trace = TRUE, data = weeddata1) : \n  singular gradient\n&quot;
## attr(,&quot;class&quot;)
## [1] &quot;try-error&quot;
## attr(,&quot;condition&quot;)
## &lt;simpleError in nls(eunsc, start = startf1, trace = TRUE, data = weeddata1): singular gradient&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nlsr)
anlxf1  &lt;-<span class="st">  </span><span class="kw">try</span>(<span class="kw">nlxb</span>(eunsc, <span class="dt">start=</span>startf1, <span class="dt">trace=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>weeddata1,
                     <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">watch=</span><span class="ot">FALSE</span>)))</code></pre></div>
<pre><code>## formula: y ~ b1/(1 + b2 * exp(-b3 * tt))
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## $watch
## [1] FALSE
## 
## $phi
## [1] 1
## 
## $lamda
## [1] 1e-04
## 
## $offset
## [1] 100
## 
## $laminc
## [1] 10
## 
## $lamdec
## [1] 4
## 
## $femax
## [1] 10000
## 
## $jemax
## [1] 5000
## 
## $rofftest
## [1] TRUE
## 
## $smallsstest
## [1] TRUE
## 
## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## Finished masks check
## datvar:[1] &quot;y&quot;  &quot;tt&quot;
## Data variable  y : [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## Data variable  tt : [1]  1  2  3  4  5  6  7  8  9 10 11 12
## trjfn:
## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x3feaa70&gt;
## no weights
## lower:[1] -Inf -Inf -Inf
## upper:[1] Inf Inf Inf
## Start:lamda: 1e-04  SS= 23756  at  b1 = 1  b2 = 1  b3 = 0.1  1 / 0
## lamda: 0.001  SS= 24356  at  b1 = 416.72  b2 = 821.43  b3 = -40.851  2 / 1
## lamda: 0.01  SS= 196562  at  b1 = 162.93  b2 = 368.16  b3 = 7.5932  3 / 1
## &lt;&lt;lamda: 0.004  SS= 10597  at  b1 = 24.764  b2 = 108.11  b3 = 31.926  4 / 1
## &lt;&lt;lamda: 0.0016  SS= 9205.5  at  b1 = 35.486  b2 = 108.11  b3 = 31.926  5 / 2
## &lt;&lt;lamda: 0.00064  SS= 9205.4  at  b1 = 35.532  b2 = 108.11  b3 = 31.926  6 / 3
## &lt;&lt;lamda: 0.000256  SS= 9205.4  at  b1 = 35.532  b2 = 108.11  b3 = 31.926  7 / 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(anlxf1)</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  9205.4  on  12 observations
##     after  4    Jacobian and  7 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               35.5321            NA         NA         NA  -6.684e-07       3.464  
## b2               108.109            NA         NA         NA  -1.464e-11   5.015e-11  
## b3               31.9262            NA         NA         NA   1.583e-09   6.427e-27</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># anlxb2  &lt;-  try(nlxb(eunsc, start=start1, trace=FALSE, data=weeddata2))</span>
<span class="co"># print(anlxb2)</span></code></pre></div>
<p>We can discover quickly the difficulty here by computing the Jacobian at this “solution” and checking its singular values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cf1 &lt;-<span class="st"> </span><span class="kw">coef</span>(anlxf1)
<span class="kw">print</span>(cf1)</code></pre></div>
<pre><code>##      b1      b2      b3 
##  35.532 108.109  31.926 
## attr(,&quot;pkgname&quot;)
## [1] &quot;nlsr&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">jf1 &lt;-<span class="st"> </span>anlxf1<span class="op">$</span>jacobian
svals &lt;-<span class="st"> </span><span class="kw">svd</span>(jf1)<span class="op">$</span>d
<span class="kw">print</span>(svals)</code></pre></div>
<pre><code>## [1] 3.4641e+00 5.0146e-11 6.4267e-27</code></pre>
<p>Here we see that the Jacobian is only rank 1, even though there are 3 coefficients. It is therefore not surprising that our nonlinear least squares program has concluded we are unable to make further progress.</p>
</div>
<div id="nonlinear-least-squares-with-functions" class="section level3">
<h3>Nonlinear least squares with functions</h3>
<p>We can run the same example as above using <strong>R</strong> functions rather than expressions, but now we need to have a gradient function as well as one to compute residuals. <strong>nlsr</strong> has tools to create these functions from expressions, as we shall see here. First we again set up the data and load the package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(nlsr)
traceval &lt;-<span class="st"> </span><span class="ot">FALSE</span>
<span class="co"># Data for Hobbs problem</span>
ydat  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, 
          <span class="fl">38.558</span>, <span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>) <span class="co"># for testing</span>
tdat  &lt;-<span class="st">  </span><span class="kw">seq_along</span>(ydat) <span class="co"># for testing</span>

<span class="co"># A simple starting vector -- must have named parameters for nlxb, nls, wrapnlsr.</span>
start1  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">b1=</span><span class="dv">1</span>, <span class="dt">b2=</span><span class="dv">1</span>, <span class="dt">b3=</span><span class="dv">1</span>)

eunsc  &lt;-<span class="st">   </span>y <span class="op">~</span><span class="st"> </span>b1<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>b2<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>b3<span class="op">*</span>tt))

<span class="kw">cat</span>(<span class="st">&quot;LOCAL DATA IN DATA FRAMES</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## LOCAL DATA IN DATA FRAMES</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weeddata1  &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">y=</span>ydat, <span class="dt">tt=</span>tdat)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weedrj &lt;-<span class="st"> </span><span class="kw">model2rjfun</span>(<span class="dt">modelformula=</span>eunsc, <span class="dt">pvec=</span>start1, <span class="dt">data=</span>weeddata1)



weedrj</code></pre></div>
<pre><code>## function (prm) 
## {
##     if (is.null(names(prm))) 
##         names(prm) &lt;- names(pvec)
##     localdata &lt;- list2env(as.list(prm), parent = data)
##     eval(residexpr, envir = localdata)
## }
## &lt;environment: 0x6892980&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rjfundoc</span>(weedrj) <span class="co"># Note how useful this is to report status</span></code></pre></div>
<pre><code>## FUNCTION weedrj 
## Formula: y ~ b1/(1 + b2 * exp(-b3 * tt))
## Code:        expression({
##     .expr3 &lt;- exp(-b3 * tt)
##     .expr5 &lt;- 1 + b2 * .expr3
##     .expr10 &lt;- .expr5^2
##     .value &lt;- b1/.expr5 - y
##     .grad &lt;- array(0, c(length(.value), 3L), list(NULL, c(&quot;b1&quot;, 
##         &quot;b2&quot;, &quot;b3&quot;)))
##     .grad[, &quot;b1&quot;] &lt;- 1/.expr5
##     .grad[, &quot;b2&quot;] &lt;- -(b1 * .expr3/.expr10)
##     .grad[, &quot;b3&quot;] &lt;- b1 * (b2 * (.expr3 * tt))/.expr10
##     attr(.value, &quot;gradient&quot;) &lt;- .grad
##     .value
## })
## Parameters:   b1, b2, b3 
## Data:         y, tt 
## 
## VALUES
## Observations:     12 
## Parameters:
## b1 b2 b3 
##  1  1  1 
## Data (length 12):
##         y tt
## 1   5.308  1
## 2   7.240  2
## 3   9.638  3
## 4  12.866  4
## 5  17.069  5
## 6  23.192  6
## 7  31.443  7
## 8  38.558  8
## 9  50.156  9
## 10 62.948 10
## 11 75.995 11
## 12 91.972 12</code></pre>
</div>
<div id="check-modelexpr-works-with-an-ssgrfun" class="section level3">
<h3>check modelexpr() works with an ssgrfun ??</h3>
</div>
<div id="test-model2rjfun-vs-model2rjfunx" class="section level3">
<h3>test model2rjfun vs model2rjfunx ??</h3>
</div>
<div id="why-is-resss-difficult-to-use-in-optimization" class="section level3">
<h3>Why is resss difficult to use in optimization?</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, <span class="fl">38.558</span>,
<span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>)
tt &lt;-<span class="st"> </span><span class="kw">seq_along</span>(y) <span class="co"># for testing</span>
mydata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y =</span> y, <span class="dt">tt =</span> tt)
f &lt;-<span class="st"> </span>y <span class="op">~</span><span class="st"> </span><span class="dv">100</span><span class="op">*</span>b1<span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">10</span><span class="op">*</span>b2 <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>b3 <span class="op">*</span><span class="st"> </span>tt))
p &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">b1 =</span> <span class="dv">1</span>, <span class="dt">b2 =</span> <span class="dv">1</span>, <span class="dt">b3 =</span> <span class="dv">1</span>)
rjfn &lt;-<span class="st"> </span><span class="kw">model2rjfun</span>(f, p, <span class="dt">data =</span> mydata)
<span class="kw">rjfn</span>(p)</code></pre></div>
<pre><code>##  [1]   4.64386   3.64458   2.25518   0.11562  -2.91533  -7.77921 -14.68094
##  [8] -20.35397 -30.41538 -41.57497 -52.89343 -67.04642
## attr(,&quot;gradient&quot;)
##            b1       b2       b3
##  [1,]  9.9519  -8.9615  0.89615
##  [2,] 10.8846  -9.6998  1.93997
##  [3,] 11.8932 -10.4787  3.14361
##  [4,] 12.9816 -11.2964  4.51856
##  [5,] 14.1537 -12.1504  6.07520
##  [6,] 15.4128 -13.0373  7.82235
##  [7,] 16.7621 -13.9524  9.76668
##  [8,] 18.2040 -14.8902 11.91213
##  [9,] 19.7406 -15.8437 14.25933
## [10,] 21.3730 -16.8050 16.80496
## [11,] 23.1016 -17.7647 19.54122
## [12,] 24.9256 -18.7127 22.45528</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">myfn &lt;-<span class="st"> </span><span class="cf">function</span>(p, <span class="dt">resfn=</span>rjfn){
  val &lt;-<span class="st"> </span><span class="kw">resss</span>(p, resfn)
}

p &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">b1 =</span> <span class="dv">2</span>, <span class="dt">b2=</span><span class="dv">2</span>, <span class="dt">b3=</span><span class="dv">1</span>)

a1 &lt;-<span class="st"> </span><span class="kw">optim</span>(p, myfn, <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">trace=</span><span class="dv">0</span>))
a1</code></pre></div>
<pre><code>## $par
##     b1     b2     b3 
## 1.9618 4.9092 3.1358 
## 
## $value
## [1] 2.5873
## 
## $counts
## function gradient 
##      200       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p>We can also embed the function directly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a2 &lt;-<span class="st"> </span><span class="kw">optim</span>(p, <span class="cf">function</span>(p,<span class="dt">resfn=</span>rjfn){<span class="kw">resss</span>(p,resfn)}, <span class="dt">control=</span><span class="kw">list</span>(<span class="dt">trace=</span><span class="dv">0</span>))
a2</code></pre></div>
<pre><code>## $par
##     b1     b2     b3 
## 1.9618 4.9092 3.1358 
## 
## $value
## [1] 2.5873
## 
## $counts
## function gradient 
##      200       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
</div>
<div id="need-more-extensive-discussion-of-simplify" class="section level3">
<h3>Need more extensive discussion of Simplify??</h3>
</div>
</div>
<div id="using-derivative-functions-to-generate-gradient-functions" class="section level2">
<h2>Using derivative functions to generate gradient functions</h2>
<p>?? from a different vignette, need to integrate</p>
<p>One of the common needs for optimization computations is the availability of accurate gradients of the objective functions. While differentiation is relatively straightforward, it is tedious and error-prone.</p>
<p>At 2015-1-24, I have not determined how to automate the use the output of the derivatives generated by <strong>nlsr</strong> to create a working gradient function. However, the following write-up shows how such a function can be generated in a semi-automatic way.</p>
<p>We use an example that appeared on the R-help mailing list on Jan 14, 2015. Responses by Ravi Varadhan and others, along with some modification I made, gave the following negative log likelihood function to be minimized.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(nlsr)

y=<span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="dv">21</span>,<span class="dv">31</span>,<span class="dv">46</span>,<span class="dv">75</span>,<span class="dv">98</span>,<span class="dv">122</span>,<span class="dv">145</span>,<span class="dv">165</span>,<span class="dv">195</span>,<span class="dv">224</span>,<span class="dv">245</span>,<span class="dv">293</span>,<span class="dv">321</span>,<span class="dv">330</span>,<span class="dv">350</span>,<span class="dv">420</span>) <span class="co"># data set</span>

Nweibull2 &lt;-<span class="st"> </span><span class="cf">function</span>(x,prm){
  la &lt;-<span class="st"> </span>prm[<span class="dv">1</span>]
  al &lt;-<span class="st"> </span>prm[<span class="dv">2</span>]
  be&lt;-<span class="st"> </span>prm[<span class="dv">3</span>]
  val2 &lt;-<span class="st"> </span>la<span class="op">*</span>be<span class="op">*</span>(x<span class="op">/</span>al)<span class="op">^</span>(be<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span><span class="st"> </span><span class="kw">exp</span>( (x<span class="op">/</span>al)<span class="op">^</span>be<span class="op">+</span>la<span class="op">*</span>al<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be) ) )
  val2
}
LL2J &lt;-<span class="st"> </span><span class="cf">function</span>(par,y) {
R =<span class="st"> </span><span class="kw">Nweibull2</span>(y,par)
<span class="op">-</span><span class="kw">sum</span>(<span class="kw">log</span>(R))
}</code></pre></div>
<p>We want the gradient of LL3J() with respect to <em>par</em>, and first compute the derivatives of Nweibull2() with respect to the paramters <em>prm</em></p>
<p>We start with the central expression in Nweibull2() and compute its partial derivatives. The expression is:</p>
<pre><code>  la*be*(x/al)^(be-1)* exp( (x/al)^be+la*al*(1-exp((x/al)^be) ) )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Put in the main expression for the Nweibull pdf.</span>
## we generate the three gradient components
g1n &lt;-<span class="st"> </span><span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span>la<span class="op">*</span>be<span class="op">*</span>(x<span class="op">/</span>al)<span class="op">^</span>(be<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span><span class="st"> </span><span class="kw">exp</span>( (x<span class="op">/</span>al)<span class="op">^</span>be<span class="op">+</span>la<span class="op">*</span>al<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be) ) ), <span class="st">&quot;la&quot;</span>)
g1n</code></pre></div>
<pre><code>## la * be * (x/al)^(be - 1) * (exp((x/al)^be + la * al * (1 - exp((x/al)^be))) * 
##     (al * (1 - exp((x/al)^be)))) + be * (x/al)^(be - 1) * exp((x/al)^be + 
##     la * al * (1 - exp((x/al)^be)))</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g2n &lt;-<span class="st"> </span><span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span>la<span class="op">*</span>be<span class="op">*</span>(x<span class="op">/</span>al)<span class="op">^</span>(be<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span><span class="st"> </span><span class="kw">exp</span>( (x<span class="op">/</span>al)<span class="op">^</span>be<span class="op">+</span>la<span class="op">*</span>al<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be) ) ), <span class="st">&quot;al&quot;</span>)
g2n</code></pre></div>
<pre><code>## la * be * (x/al)^(be - 1) * (exp((x/al)^be + la * al * (1 - exp((x/al)^be))) * 
##     (be * (x/al)^(be - 1) * -(x/al^2) + (la * al * -(exp((x/al)^be) * 
##         (be * (x/al)^(be - 1) * -(x/al^2))) + la * (1 - exp((x/al)^be))))) + 
##     la * be * ((be - 1) * (x/al)^(be - 1 - 1) * -(x/al^2)) * 
##         exp((x/al)^be + la * al * (1 - exp((x/al)^be)))</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g3n &lt;-<span class="st"> </span><span class="kw">nlsDeriv</span>(<span class="op">~</span><span class="st"> </span>la<span class="op">*</span>be<span class="op">*</span>(x<span class="op">/</span>al)<span class="op">^</span>(be<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span><span class="st"> </span><span class="kw">exp</span>( (x<span class="op">/</span>al)<span class="op">^</span>be<span class="op">+</span>la<span class="op">*</span>al<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be) ) ), <span class="st">&quot;be&quot;</span>)
g3n</code></pre></div>
<pre><code>## la * be * (x/al)^(be - 1) * (exp((x/al)^be + la * al * (1 - exp((x/al)^be))) * 
##     ((x/al)^be * log(x/al) + la * al * -(exp((x/al)^be) * ((x/al)^be * 
##         log(x/al))))) + (la * be * ((x/al)^(be - 1) * log(x/al)) + 
##     la * (x/al)^(be - 1)) * exp((x/al)^be + la * al * (1 - exp((x/al)^be)))</code></pre>
<p>By copying and pasting the output above into a function structure, we get Nwei2g() below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Nwei2g &lt;-<span class="st"> </span><span class="cf">function</span>(x, prm){
  la &lt;-<span class="st"> </span>prm[<span class="dv">1</span>]
  al &lt;-<span class="st"> </span>prm[<span class="dv">2</span>]
  be&lt;-<span class="st"> </span>prm[<span class="dv">3</span>]
g1v &lt;-<span class="st"> </span>la <span class="op">*</span><span class="st"> </span>be <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(<span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">+</span><span class="st"> </span>la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be))) <span class="op">*</span><span class="st"> </span>
<span class="st">    </span>(al <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be)))) <span class="op">+</span><span class="st"> </span>be <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be)))

g2v &lt;-<span class="st"> </span>la <span class="op">*</span><span class="st"> </span>be <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(<span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">+</span><span class="st"> </span>la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be))) <span class="op">*</span><span class="st"> </span>
<span class="st">    </span>(be <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="op">-</span>(x<span class="op">/</span>al<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>(la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span><span class="op">-</span>(<span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be) <span class="op">*</span><span class="st"> </span>
<span class="st">        </span>(be <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="op">-</span>(x<span class="op">/</span>al<span class="op">^</span><span class="dv">2</span>))) <span class="op">+</span><span class="st"> </span>la <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be))))) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>la <span class="op">*</span><span class="st"> </span>be <span class="op">*</span><span class="st"> </span>((be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="op">-</span>(x<span class="op">/</span>al<span class="op">^</span><span class="dv">2</span>)) <span class="op">*</span><span class="st"> </span>
<span class="st">        </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">+</span><span class="st"> </span>la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be)))

g3v &lt;-<span class="st"> </span>la <span class="op">*</span><span class="st"> </span>be <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(<span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">+</span><span class="st"> </span>la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be))) <span class="op">*</span><span class="st"> </span>
<span class="st">    </span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(x<span class="op">/</span>al) <span class="op">+</span><span class="st"> </span>la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span><span class="op">-</span>(<span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be) <span class="op">*</span><span class="st"> </span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">*</span><span class="st"> </span>
<span class="st">        </span><span class="kw">log</span>(x<span class="op">/</span>al))))) <span class="op">+</span><span class="st"> </span>(la <span class="op">*</span><span class="st"> </span>be <span class="op">*</span><span class="st"> </span>((x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(x<span class="op">/</span>al)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>la <span class="op">*</span><span class="st"> </span>(x<span class="op">/</span>al)<span class="op">^</span>(be <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be <span class="op">+</span><span class="st"> </span>la <span class="op">*</span><span class="st"> </span>al <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>((x<span class="op">/</span>al)<span class="op">^</span>be)))
gg &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data=</span><span class="kw">c</span>(g1v, g2v, g3v), <span class="dt">ncol=</span><span class="dv">3</span>)
}</code></pre></div>
<p>We can check this gradient functionusing the grad() function from package <strong>numDeriv</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">start1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">lambda=</span>.<span class="dv">01</span>,<span class="dt">alpha=</span><span class="dv">340</span>,<span class="dt">beta=</span>.<span class="dv">8</span>)
start2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">lambda=</span>.<span class="dv">01</span>,<span class="dt">alpha=</span><span class="dv">340</span>,<span class="dt">beta=</span>.<span class="dv">7</span>)

<span class="kw">require</span>(numDeriv)
ganwei &lt;-<span class="st"> </span><span class="kw">Nwei2g</span>(y, <span class="dt">prm=</span>start1)

<span class="kw">require</span>(numDeriv)
Nw &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) {
   <span class="kw">Nweibull2</span>(y, x)
} <span class="co"># to allow grad() to work</span>

gnnwei &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span><span class="kw">length</span>(y), <span class="dt">ncol=</span><span class="dv">3</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)){
   gnrow &lt;-<span class="st"> </span><span class="kw">grad</span>(Nw, <span class="dt">x=</span>start1, <span class="dt">y=</span>y[i])
   gnnwei[i,] &lt;-<span class="st"> </span>gnrow
}
gnnwei</code></pre></div>
<pre><code>##             [,1]        [,2]        [,3]
##  [1,]  1.5080091  7.5763e-06 -4.4573e-02
##  [2,]  1.0470119  4.3477e-06 -2.1663e-02
##  [3,]  0.6473921  1.6572e-06 -7.3707e-03
##  [4,]  0.4021585  1.7784e-07 -9.4940e-04
##  [5,]  0.1635446 -1.0061e-06  3.5893e-03
##  [6,] -0.0815624 -1.6713e-06  6.0571e-03
##  [7,] -0.1689654 -1.5386e-06  5.8709e-03
##  [8,] -0.2048835 -1.1819e-06  5.0149e-03
##  [9,] -0.2077443 -7.9701e-07  4.0222e-03
## [10,] -0.1955391 -4.9171e-07  3.1859e-03
## [11,] -0.1644138 -1.3523e-07  2.1110e-03
## [12,] -0.1297028  8.2595e-08  1.3249e-03
## [13,] -0.1055059  1.7196e-07  9.0488e-04
## [14,] -0.0598567  2.2613e-07  3.1939e-04
## [15,] -0.0406518  2.0242e-07  1.4872e-04
## [16,] -0.0355949  1.9079e-07  1.1187e-04
## [17,] -0.0261120  1.6182e-07  5.3031e-05
## [18,] -0.0075317  6.8245e-08 -1.1995e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ganwei</code></pre></div>
<pre><code>##             [,1]        [,2]        [,3]
##  [1,]  1.5080091  7.5763e-06 -4.4573e-02
##  [2,]  1.0470119  4.3477e-06 -2.1663e-02
##  [3,]  0.6473921  1.6572e-06 -7.3707e-03
##  [4,]  0.4021585  1.7784e-07 -9.4940e-04
##  [5,]  0.1635446 -1.0061e-06  3.5893e-03
##  [6,] -0.0815624 -1.6713e-06  6.0571e-03
##  [7,] -0.1689654 -1.5386e-06  5.8709e-03
##  [8,] -0.2048835 -1.1819e-06  5.0149e-03
##  [9,] -0.2077443 -7.9701e-07  4.0222e-03
## [10,] -0.1955391 -4.9171e-07  3.1859e-03
## [11,] -0.1644138 -1.3523e-07  2.1110e-03
## [12,] -0.1297028  8.2595e-08  1.3249e-03
## [13,] -0.1055059  1.7196e-07  9.0488e-04
## [14,] -0.0598567  2.2613e-07  3.1939e-04
## [15,] -0.0406518  2.0242e-07  1.4872e-04
## [16,] -0.0355949  1.9079e-07  1.1187e-04
## [17,] -0.0261120  1.6182e-07  5.3031e-05
## [18,] -0.0075317  6.8245e-08 -1.1995e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cat</span>(<span class="st">&quot;max(abs(gnnwei - ganwei))= &quot;</span>,   <span class="kw">max</span>(<span class="kw">abs</span>(gnnwei <span class="op">-</span><span class="st"> </span>ganwei)),<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</code></pre></div>
<pre><code>## max(abs(gnnwei - ganwei))=  2.8041e-11</code></pre>
<p>Now we can build the gradient of the objective function. This requires an application of the chain rule to the summation of logs of the elements of the quantity <em>R</em>. Since the derivative of log(R) w.r.t. R is simply 1/R, this is relatively simple. However, I have not found how to automate this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## and now we can build the gradient of LL2J
LL2Jg &lt;-<span class="st"> </span><span class="cf">function</span>(prm, y) {
    R =<span class="st"> </span><span class="kw">Nweibull2</span>(y,prm)
    gNN &lt;-<span class="st"> </span><span class="kw">Nwei2g</span>(y, prm)
<span class="co">#    print(str(gNN)</span>
    gL &lt;-<span class="st"> </span><span class="op">-</span><span class="st"> </span><span class="kw">as.vector</span>( <span class="kw">t</span>(<span class="dv">1</span><span class="op">/</span>R) <span class="op">%*%</span><span class="st"> </span>gNN) 
}
<span class="co"># test</span>
gaLL2J &lt;-<span class="st"> </span><span class="kw">LL2Jg</span>(start1, y)
gaLL2J</code></pre></div>
<pre><code>## [1] 3365.78244   -0.01441  -18.63351</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gnLL2J &lt;-<span class="st"> </span><span class="kw">grad</span>(LL2J, start1, <span class="dt">y=</span>y)
gnLL2J</code></pre></div>
<pre><code>## [1] 3365.78244   -0.01441  -18.63351</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cat</span>(<span class="st">&quot;max(abs(gaLL2J-gnLL2J))= &quot;</span>, <span class="kw">max</span>(<span class="kw">abs</span>(gaLL2J<span class="op">-</span>gnLL2J)), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span> )</code></pre></div>
<pre><code>## max(abs(gaLL2J-gnLL2J))=  1.8254e-08</code></pre>
</div>
<div id="appendix-a-providing-exogenous-data" class="section level2">
<h2>Appendix A: Providing exogenous data</h2>
<p>These examples show dotargs do NOT work for any of nlsr, nls, or minpack.lm. Use of a dataframe or local (calling) environment objects does work in all.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># try different ways of supplying data to R nls stuff</span>
ydata &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">5.308</span>, <span class="fl">7.24</span>, <span class="fl">9.638</span>, <span class="fl">12.866</span>, <span class="fl">17.069</span>, <span class="fl">23.192</span>, <span class="fl">31.443</span>, <span class="fl">38.558</span>,
<span class="fl">50.156</span>, <span class="fl">62.948</span>, <span class="fl">75.995</span>, <span class="fl">91.972</span>)
ttdata &lt;-<span class="st"> </span><span class="kw">seq_along</span>(ydata) <span class="co"># for testing</span>

mydata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y =</span> ydata, <span class="dt">tt =</span> ttdata)

hobsc &lt;-<span class="st"> </span>y <span class="op">~</span><span class="st"> </span><span class="dv">100</span><span class="op">*</span>b1<span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">10</span><span class="op">*</span>b2 <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span><span class="st"> </span>b3 <span class="op">*</span><span class="st"> </span>tt))

ste &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">b1 =</span> <span class="dv">2</span>, <span class="dt">b2 =</span> <span class="dv">5</span>, <span class="dt">b3 =</span> <span class="dv">3</span>)

<span class="co"># let's try finding the variables</span>

findmainenv &lt;-<span class="st"> </span><span class="cf">function</span>(formula, prm) {
   vn &lt;-<span class="st"> </span><span class="kw">all.vars</span>(formula)
   pnames &lt;-<span class="st"> </span><span class="kw">names</span>(prm)
   ppos &lt;-<span class="st"> </span><span class="kw">match</span>(pnames, vn)
   datvar &lt;-<span class="st"> </span>vn[<span class="op">-</span>ppos]
   <span class="kw">cat</span>(<span class="st">&quot;Data variables:&quot;</span>)
   <span class="kw">print</span>(datvar)
   <span class="kw">cat</span>(<span class="st">&quot;Are the variables present in the current working environment?</span><span class="ch">\n</span><span class="st">&quot;</span>)
   <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(datvar)){
       <span class="kw">cat</span>(datvar[[i]],<span class="st">&quot; : present=&quot;</span>,<span class="kw">exists</span>(datvar[[i]]),<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
   }
}


<span class="kw">findmainenv</span>(hobsc, ste)</code></pre></div>
<pre><code>## Data variables:[1] &quot;y&quot;  &quot;tt&quot;
## Are the variables present in the current working environment?
## y  : present= TRUE 
## tt  : present= TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span>ydata
tt &lt;-<span class="st"> </span>ttdata
<span class="kw">findmainenv</span>(hobsc, ste)</code></pre></div>
<pre><code>## Data variables:[1] &quot;y&quot;  &quot;tt&quot;
## Are the variables present in the current working environment?
## y  : present= TRUE 
## tt  : present= TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rm</span>(y)
<span class="kw">rm</span>(tt)

<span class="co"># ===============================</span>


<span class="co"># let's try finding the variables in dotargs</span>

finddotargs &lt;-<span class="st"> </span><span class="cf">function</span>(formula, prm, ...) {
   dots &lt;-<span class="st"> </span><span class="kw">list</span>(...)
   <span class="kw">cat</span>(<span class="st">&quot;dots:&quot;</span>)
   <span class="kw">print</span>(dots)
   <span class="kw">cat</span>(<span class="st">&quot;names in dots:&quot;</span>)
   dtn &lt;-<span class="st"> </span><span class="kw">names</span>(dots)
   <span class="kw">print</span>(dtn)
   vn &lt;-<span class="st"> </span><span class="kw">all.vars</span>(formula)
   pnames &lt;-<span class="st"> </span><span class="kw">names</span>(prm)
   
   ppos &lt;-<span class="st"> </span><span class="kw">match</span>(pnames, vn)
   datvar &lt;-<span class="st"> </span>vn[<span class="op">-</span>ppos]
   <span class="kw">cat</span>(<span class="st">&quot;Data variables:&quot;</span>)
   <span class="kw">print</span>(datvar)
   <span class="kw">cat</span>(<span class="st">&quot;Are the variables present in the dot args?</span><span class="ch">\n</span><span class="st">&quot;</span>)
   <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(datvar)){
       dname &lt;-<span class="st"> </span>datvar[[i]]
       <span class="kw">cat</span>(dname,<span class="st">&quot; : present=&quot;</span>,(dname <span class="op">%in%</span><span class="st"> </span>dtn),<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
   }
}

<span class="kw">finddotargs</span>(hobsc, ste, <span class="dt">y=</span>ydata, <span class="dt">tt=</span>ttdata)</code></pre></div>
<pre><code>## dots:$y
##  [1]  5.308  7.240  9.638 12.866 17.069 23.192 31.443 38.558 50.156 62.948
## [11] 75.995 91.972
## 
## $tt
##  [1]  1  2  3  4  5  6  7  8  9 10 11 12
## 
## names in dots:[1] &quot;y&quot;  &quot;tt&quot;
## Data variables:[1] &quot;y&quot;  &quot;tt&quot;
## Are the variables present in the dot args?
## y  : present= TRUE 
## tt  : present= TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ===============================</span>

y &lt;-<span class="st"> </span>ydata
tt &lt;-<span class="st"> </span>ttdata
tryq &lt;-<span class="st"> </span><span class="kw">try</span>(nlsquiet &lt;-<span class="st"> </span><span class="kw">nls</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste))
<span class="cf">if</span> (<span class="kw">class</span>(tryq) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlsquiet)} <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;try-error</span><span class="ch">\n</span><span class="st">&quot;</span>)}</code></pre></div>
<pre><code>## Nonlinear regression model
##   model: y ~ 100 * b1/(1 + 10 * b2 * exp(-0.1 * b3 * tt))
##    data: parent.frame()
##   b1   b2   b3 
## 1.96 4.91 3.14 
##  residual sum-of-squares: 2.59
## 
## Number of iterations to convergence: 4 
## Achieved convergence tolerance: 2.17e-07</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- OK</span>
<span class="kw">rm</span>(y)
<span class="kw">rm</span>(tt)


tdots&lt;-<span class="kw">try</span>(nlsdots &lt;-<span class="st"> </span><span class="kw">nls</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">y=</span>ydata, <span class="dt">tt=</span>ttdata))
<span class="cf">if</span> ( <span class="kw">class</span>(tdots) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlsdots)} <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;try-error</span><span class="ch">\n</span><span class="st">&quot;</span>)}</code></pre></div>
<pre><code>## try-error</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- Fails</span>
tframe &lt;-<span class="st"> </span><span class="kw">try</span>(nlsframe &lt;-<span class="st"> </span><span class="kw">nls</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">data=</span>mydata))
<span class="cf">if</span> (<span class="kw">class</span>(tframe) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlsframe)} <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;try-error</span><span class="ch">\n</span><span class="st">&quot;</span>)}</code></pre></div>
<pre><code>## Nonlinear regression model
##   model: y ~ 100 * b1/(1 + 10 * b2 * exp(-0.1 * b3 * tt))
##    data: mydata
##   b1   b2   b3 
## 1.96 4.91 3.14 
##  residual sum-of-squares: 2.59
## 
## Number of iterations to convergence: 4 
## Achieved convergence tolerance: 2.17e-07</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- OK</span>

<span class="kw">library</span>(nlsr)
y &lt;-<span class="st"> </span>ydata
tt &lt;-<span class="st"> </span>ttdata
tquiet &lt;-<span class="st"> </span><span class="kw">try</span>(nlsrquiet &lt;-<span class="st"> </span><span class="kw">nlxb</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste))</code></pre></div>
<pre><code>## vn:[1] &quot;y&quot;  &quot;b1&quot; &quot;b2&quot; &quot;b3&quot; &quot;tt&quot;
## no weights</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">if</span> ( <span class="kw">class</span>(tquiet) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlsrquiet)}</code></pre></div>
<pre><code>## nlsr object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  5    Jacobian and  6 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               1.96186        0.1131      17.35  3.167e-08  -2.603e-09       130.1  
## b2               4.90916        0.1688      29.08  3.284e-10  -2.425e-10       6.165  
## b3                3.1357       0.06863      45.69  5.768e-12   1.943e-09       2.735</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- OK</span>
<span class="kw">rm</span>(y)
<span class="kw">rm</span>(tt)
test &lt;-<span class="st"> </span><span class="kw">try</span>(nlsrdots &lt;-<span class="st"> </span><span class="kw">nlxb</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">y=</span>ydata, <span class="dt">tt=</span>ttdata))
  <span class="cf">if</span> (<span class="kw">class</span>(test) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) { <span class="kw">print</span>(nlsrdots) } <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;Try error</span><span class="ch">\n</span><span class="st">&quot;</span>) }</code></pre></div>
<pre><code>## Try error</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- Note -- does NOT work -- do we need to specify the present env. in nlfb for y, tt??</span>
test2 &lt;-<span class="st"> </span><span class="kw">try</span>(nlsframe &lt;-<span class="st"> </span><span class="kw">nls</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">data=</span>mydata))
<span class="cf">if</span> (<span class="kw">class</span>(test) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlsframe) } <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;Try error</span><span class="ch">\n</span><span class="st">&quot;</span>) }</code></pre></div>
<pre><code>## Try error</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- OK</span>


<span class="kw">library</span>(minpack.lm)
y &lt;-<span class="st"> </span>ydata
tt &lt;-<span class="st"> </span>ttdata
nlsLMquiet &lt;-<span class="st"> </span><span class="kw">nlsLM</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste)
<span class="kw">print</span>(nlsLMquiet)</code></pre></div>
<pre><code>## Nonlinear regression model
##   model: y ~ 100 * b1/(1 + 10 * b2 * exp(-0.1 * b3 * tt))
##    data: parent.frame()
##   b1   b2   b3 
## 1.96 4.91 3.14 
##  residual sum-of-squares: 2.59
## 
## Number of iterations to convergence: 4 
## Achieved convergence tolerance: 1.49e-08</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- OK</span>
<span class="kw">rm</span>(y)
<span class="kw">rm</span>(tt)
## Dotargs
tdots &lt;-<span class="st"> </span><span class="kw">try</span>(nlsLMdots &lt;-<span class="st"> </span><span class="kw">nlsLM</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">y=</span>ydata, <span class="dt">tt=</span>ttdata))
<span class="cf">if</span> (<span class="kw">class</span>(tdots) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) { <span class="kw">print</span>(nlsLMdots) } <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;try-error</span><span class="ch">\n</span><span class="st">&quot;</span>) }</code></pre></div>
<pre><code>## try-error</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#-  Note -- does NOT work</span>
## dataframe
tframe &lt;-<span class="st"> </span><span class="kw">try</span>(nlsLMframe &lt;-<span class="st"> </span><span class="kw">nlsLM</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">data=</span>mydata) )
<span class="cf">if</span> (<span class="kw">class</span>(tdots) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlsLMframe)} <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;try-error</span><span class="ch">\n</span><span class="st">&quot;</span>) }</code></pre></div>
<pre><code>## try-error</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- does not work</span>

<span class="kw">detach</span>(<span class="st">&quot;package:nlsr&quot;</span>, <span class="dt">unload=</span><span class="ot">TRUE</span>)
<span class="kw">library</span>(nlmrt)
txq &lt;-<span class="st"> </span><span class="kw">try</span>( nlxbquiet &lt;-<span class="st"> </span><span class="kw">nlxb</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste))
<span class="cf">if</span> (<span class="kw">class</span>(txq) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlxbquiet)} <span class="cf">else</span> { <span class="kw">cat</span>(<span class="st">&quot;try-error</span><span class="ch">\n</span><span class="st">&quot;</span>)}</code></pre></div>
<pre><code>## try-error</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- Note -- does NOT work</span>
txdots &lt;-<span class="st"> </span><span class="kw">try</span>( nlxbdots &lt;-<span class="st"> </span><span class="kw">nlxb</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">y=</span>y, <span class="dt">tt=</span>tt) )
<span class="cf">if</span> (<span class="kw">class</span>(txdots) <span class="op">!=</span><span class="st"> &quot;try-error&quot;</span>) {<span class="kw">print</span>(nlxbdots)} <span class="cf">else</span> {<span class="kw">cat</span>(<span class="st">&quot;try-error</span><span class="ch">\n</span><span class="st">&quot;</span>)}</code></pre></div>
<pre><code>## try-error</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- Note -- does NOT work</span>
## dataframe
nlxbframe &lt;-<span class="st"> </span><span class="kw">nlxb</span>(<span class="dt">formula=</span>hobsc, <span class="dt">start=</span>ste, <span class="dt">data=</span>mydata)
<span class="kw">print</span>(nlxbframe)</code></pre></div>
<pre><code>## nlmrt class object: x 
## residual sumsquares =  2.5873  on  12 observations
##     after  5    Jacobian and  6 function evaluations
##   name            coeff          SE       tstat      pval      gradient    JSingval   
## b1               1.96186        0.1131      17.35  3.167e-08  -2.612e-09       130.1  
## b2               4.90916        0.1688      29.08  3.284e-10  -2.402e-10       6.165  
## b3                3.1357       0.06863      45.69  5.768e-12   1.933e-09       2.735</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#- OK</span></code></pre></div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-BatesWatts81">
<p>Bates, Douglas M., and Donald G. Watts. 1981. “A Relative Off Set Orthogonality Convergence Criterion for Nonlinear Least Squares.” <em>Technometrics</em> 23 (2): 179–83.</p>
</div>
<div id="ref-Hartley61">
<p>Hartley, H. O. 1961. “The Modified Gauss-Newton Method for Fitting of Nonlinear Regression Functions by Least Squares.” <em>Technometrics</em> 3: 269–80.</p>
</div>
<div id="ref-Marq63">
<p>Marquardt, Donald W. 1963. “An Algorithm for Least-Squares Estimation of Nonlinear Parameters.” <em>SIAM Journal on Applied Mathematics</em> 11 (2). SIAM: 431–41.</p>
</div>
<div id="ref-jn77ima">
<p>Nash, John C. 1977. “Minimizing a Nonlinear Sum of Squares Function on a Small Computer.” <em>Journal of the Institute for Mathematics and Its Applications</em> 19: 231–37.</p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
